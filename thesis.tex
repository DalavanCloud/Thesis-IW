\documentclass[10pt,a4paper]{report}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}


\begin{document}
\title{Direct Moving Transmitter Geolocation Based on Delay and Doppler}
\author{\textbf{Itamar Weiss}\\
  The Iby and Aladar Fleischman Faculty of Engineering,\\
  Tel-Aviv University}  
\date{\today}
\maketitle

\begin{abstract}
We analyze the problem of locating a single moving transmitter using an array of L stationary receivers, in a one-step algorithm. We will start with an analysis of narrow band signals, and will later expand the analysis to wide band signals.\\

Task List:
\begin{itemize}
\item Fix the Cramer-Rao chapter - equations and replacing $\tilde{f_\ell}$ with $f_\ell$
\item Write introduction for the Cramer-Rao chapter
\item Bold for all the matrices
\item Replace $l$ with $\ell$
\item Replace $Re$ and $Im$ with $\Re$ and $\Im$.
\item Simulate conventional methods.
\item Simulate Kalman filter for the dynamic model.
\item Simulate $L_2$ derivatives to visually check if they are correct.
\item Write introduction for the simulation chapter.
\item Validate the Stein Formula for finding TDOA and FDOA.
\item Validate the Gauss-Newton Equations
\item Run simulations
\item Write conclusions for the $L_2$ Analysis chapter and for the CRB chapter
\item List of symbols
\item List of abbreviations
\end{itemize}
\end{abstract}

\tableofcontents

\listoffigures

\chapter{Introduction and Literature Survey}
In this work, we analyse the problem of passive geolocation of a moving transmitter, using
a stationary array of receivers. We suggest a one-step algorithm for estimating the position and velocity of the transmitter based on one sampling interval. The performance of this algorithm is analyzed, tested using Monte-Carlo simulations and compared to the performance of conventional methods.\\

The signal processing problem of passive transmitter geolocation has been greatly discussed since World War I. It has both civil and military related applications. Among the military applications we can mention geolocation of communication systems, radars, GPS blockers and passive low-signature geolocation of air-planes. Among the civil applications we can mention navigation. The extensive use of cellular telephony these days has increased the popularity of this field, and geolocation of cellular phone users is one of the major civil application nowadays, for focused advertising, network load monitoring and enhanced emergency services. For example, see the wireless enhanced 911 (E911) review by Zagami et al.\cite{zagami}.\\

Unlike active localization systems such as radar or sonar, that transmit a known signal and process the signal after it was returned from the target, in passive gelocation systems the transmitted signal is usually unknown. In scenarios in which the transmitted signal is known, better performance and lower algorithm complexity can be achieved.\\

While exploring passive geolocation methods, two main approaches can be found: two-step methods and one-step methods. Many two-step methods for passive transmitter geolocation have been suggested in the past. The two-step methods first estimate parametrs characterizing the signal in each receiver, or in each pair of receivers, and then use these estimated parameters to estimate the location of the transmitter. Obviously, due the incomplete data used in each receiver or pair of receivers and over-parametrization, two-step methods are sub-optimal. Recently, one-step methods (\cite{dpd},\cite{dpd_nb}) have been suggested and shown to have greater results than the one-step methods. The one-step methods use the sampled signals collected at each of the receivers to simultaneously estimate the position of the transmitter.\\

Although geolocation of a stationary transmitter by moving receivers has been discussed thoroughly, the problem of geolocating a moving transmitter has been less discussed. The problem of geolocating a moving transmitter shows greater complexity than geolocating a stationary transmitter, because both the position and velocity of the transmitter are unknown and need to be estimated.\\

In this work, we employ the concepts of the one-step methods for passive geolocation of a moving transmitter. \\

In the following chapter, we introduce the two-step and one-step methods suggested for passive geolocation of a stationary transmitter based on delay and doppler.
The two-steps methods we introduce are TDOA and FDOA, while the one-step methods introduced are DPD and its derivatives.\\
At the last section of this chapter, we introduce the outline for our work.

\section{Two-Step Localization Methods}
\subsection{Extracting TDOA and FDOA measurements}
The first step in time and frequency shifts based two-step methods is estimating the time and frequency shifts between the received signal and another signal. Depending on the method, the estimation can be used between each pair of receivers, between all the receivers and a reference receiver, or between each receiver and a known reference signal, in the case where the transmitted signal is known.\\

The ML estimation of the delay and Doppler suggested by S. Stein \cite{stein} presents the following formulation.
Two noisy signal $y_1(t)$ and $y_2(t)$, observed over the interval $(0,T)$, are assumed to contain a common signal $x(t)$, appearing in $y_2(t)$ with a relative complex gain factor $\alpha$, at a differential delay $\tau$ and with a frequency offset $\nu$, all unknown. In complex envelope notation:
\begin{eqnarray}
y_1(t) &=& x(t)+n_1(t)\\
y_2(t) &=& \alpha x(t+\tau)e^{2 \pi j \nu (t+\tau)} + n_2(t) \nonumber
\end{eqnarray}

For spectrally flat noise, the ML suggested estimator is shown to be the maximum of the complex cross-ambiguity function.
\begin{equation}
R(\tau,\nu) = \left|\frac{1}{T}\int e^{-2 \pi j f \tau} Y_1^*(f-\nu)Y_2(f)df\right|
\end{equation}
Or in the time domain:
\begin{equation}
R(\tau,\nu) = \left|\frac{1}{T}\int e^{-2 \pi j \nu t} y_1^*(t+\tau)y_2(t)dt\right|
\end{equation}
And in the discrete time domain:
\begin{equation}
R(\tau,\nu) = \left|\frac{1}{N} \sum_{n=0}^{N-1} e^{-2 \pi j \nu t_n} y_1^*[n+m]y_2[n]\right|
\end{equation}
Where $m=\lfloor \tau F_s \rfloor$ is the discrete time delay, $N$ is the number of samples in the interval, $t_n = \frac{1}{F_s}n$ and $F_s$ is the sampling frequency.

\subsection{TDOA Based Passive Geolocation}
In this subsection we will discuss the methods to geolocate a transmitter using TOA and TDOA measurements.\\
Assuming that the TOA of the Signal-Of-Interest(SOI) to a receiver is known, the transmitter is known to be located on a sphere around the receiver. \\
Adding a second receiver will limit the location of the transmitter to a circle. Using another receiver will limit the location of the transmitter to two possible points of intersection, that using additional a-priori information about the location of the transmitter can reduce the estimation to a single position.\\
In the case that additional receivers are added, the spheres will not intersect in one point because of noise that causes estimation errors of the TOA, and the need to use estimation methods arises.\\

TOA methods for passive geolocation are seldom used, because in order to measure the TOA, each receiver needs to know the time when the signal was transmitted, which is usually unknown.
Therefore, the more common methods use the TDOA measurements between pairs of receivers.\\

Each TDOA measurement locates the transmitter on a hyperboloid. Two TDOA measurements locate the transmitter on two curves of intersection, and a third measurement can locate the receivers at two single points. Using a-priori information about the transmitter location the two possible points can be reduced to a single solution.
Again, as additional receivers are added, the hyperboloids will not intersect in one point because of noisy measurements, and the need to use estimation methods arises.
Chan and Ho \cite{chan_and_ho} suggested a simple and efficient estimator for hyperbolic location systems, and Chestnut \cite{chestnut} suggested a method for estimating the position of a stationary transmitter based on TDOA measurements and analysed its performance.\\

It is interesting to mention that the TDOA estimated in a single interval contains no information regarding the velocity of the transmitter. Thus, the velocity of the transmitter cannot be estimated using the TDOA measurements.\\

There are many suggested methods for estimating the position of a transmitter based on TDOA measurements. We will shortly introduce the application of the Weighted-Least-Squares(WLS) method, because of its simplicity, and only to acquire some intuition.\\

In the first step of the method introduced, the difference in the time-of-arrival is estimated for every pair of receivers, so that the matrix $\hat{T}$ is estimated. The $i,j$-th element of the matrix $\hat{T}$ is the time-of-arrival difference between the $i$-th and the $j$-th receiver.\\


For transmitter position $\vec{p}$, and receivers positions $\vec{p_\ell}$, the expected $T(\vec{p})$ matrix can be calculated:
\begin{equation}
T(\vec{p})_{i,j} = \frac{1}{C}\|\vec{p_i}-\vec{p}\|-\frac{1}{C}\|\vec{p_j}-\vec{p}\|
\end{equation}
A WLS cost function can then be defined as:
\begin{equation}
C_T(\vec{p}) = \sum_{i=1}^L \sum_{j=1}^L W_{i,j}(T(\vec{p})_{i,j}-\hat{T}_{i,j})^2
\end{equation}
And the LS estimator for the position is:
\begin{equation}
\hat{\vec{p}} = argmax_{\vec{p}}C_{TDOA}(\vec{p})
\end{equation}

The Known-Signals Cramer-Rao lower bound related to the TDOA estimation of the $\ell$-th signal is:
\begin{equation}
{FIM}_\ell = \frac{2}{\sigma_\ell^2}\left\|\frac{\partial \mathbf{m_\ell}}{\partial T_\ell}\right\|^2
\end{equation}
Where all of the other elements of the FIM outside the diagonal are zero. And Thus:
\begin{equation}
{CRB}_\ell = \frac{\sigma_\ell^2}{2\left\|\frac{\partial \mathbf{m_\ell}}{\partial T_\ell}\right\|^2}
\end{equation}

Assuming that the TDOA measurements were taken using an efficient estimator, the CRB can be used to determine the weights matrix $W$.

\subsection{FDOA Based Passive Geolocation}
When the transmitter is moving with a relative radial velocity to the receiver, a frequency shift of the transmitted signal is caused due to the Doppler effect.\\
Similarly to the TDOA based methods, the exact original transmitted frequency is usually unknown, and requires measurement of the FDOA between each pair of receivers.
The methods that use these measurements are sometimes also referred to as DD.\\

FDOA measurements contain information on both the position and velocity of the transmitter, unlike TDOA measurements that only contain information about the position of the transmitter. \\
Nevertheless, in order to acquire the FDOA measurements, a relative motion of the transmitter and the receivers is necessary, limiting the scenarios applicable for this method.\\

A geometrical interpretation of the FDOA estimation methods is less direct, but is possible if we limit the discussion to a simpler scenario. Consider a scenario in which the transmitter is stationary and the receiver is moving in a constant known velocity $\vec{v}$. The Doppler frequency shift will be proportional to the relative radial velocity $\|\vec{v}\|cos\theta$, where $\theta$ is the angle between the velocity and the line connecting the transmitter and the receiver. Since $\vec{v}$ is known, $cos\theta$ can be estimated and a cone on which the transmitter is located is defined.\\
Additional receivers create additional cones that the transmitter lies in their spatial intersection.\\

Just in order to acquire some understanding of the FDOA methods, we will introduce a simple WLS estimation method for passive geolocation of a moving transmitter.\\

In the first step of the method introduced, the difference in the frequency-of-arrival is estimated for every pair of receivers, so that the matrix $\hat{F}$ is estimated. The $i,j$-th element of the matrix $\hat{F}$ is the frequency-of-arrival difference between the $i$-th and the $j$-th receiver.\\

For transmitter position and velocity $(\vec{p},\vec{v})$, the expected $F(\vec{p},\vec{v})$ matrix can be calculated:
\begin{equation}
F(\vec{p},\vec{v})_{i,j} = -\frac{F_c}{c}\frac{(\vec{v}-\vec{v_i})(\vec{p}-\vec{p_i})}{|\vec{p}-\vec{p_i}|}+\frac{F_c}{c}\frac{(\vec{v}-\vec{v_j})(\vec{p}-\vec{p_j})}{|\vec{p}-\vec{p_j}|}
\end{equation}
Where $F_c$ is the carrier frequency of the signal, $c$ is the propagation speed of the signal, $\vec{v}$ is the velocity of the transmitter and $\vec{v_i}$ is the velocity of the $i$-th receiver.\\

A WLS cost function can then be defined as:
\begin{equation}
C_F(\vec{p},\vec{v}) = \sum_{i=1}^L \sum_{j=1}^L W_{i,j}(F(\vec{p},\vec{v})_{i,j}-\hat{F}_{i,j})^2
\end{equation}
And the WLS estimator for the position and velocity of the transmitter is:
\begin{equation}
(\hat{\vec{p}},\hat{\vec{v}}) = argmax_{(\vec{p},\vec{v})}C_{FDOA}(\vec{p},\vec{v})
\end{equation}
As opposed to the TDOA estimator, we can see that the FDOA estimate depends both on the position and on the velocity of the transmitter. Thus, both the position and velocity of the transmitter can be estimated using the FDOA measurements.\\

The Known-Signals Cramer-Rao lower bound related to the FDOA estimation of the $\ell$-th signal is:
\begin{equation}
{FIM}_\ell = \frac{2}{\sigma_\ell^2}\left\|\frac{\partial \mathbf{m_\ell}}{\partial \tilde{f}_\ell}\right\|^2
\end{equation}
Where all of the other elements of the FIM outside the diagonal are zero. And Thus:
\begin{equation}
{CRB}_\ell = \frac{\sigma_\ell^2}{2\left\|\frac{\partial \mathbf{m_\ell}}{\partial \tilde{f}_\ell}\right\|^2}
\end{equation}
Assuming that the FDOA measurements were taken using an efficient estimator, the CRB can be used to determine the weights matrix $W$.

\subsection{TDOA-FDOA Based Passive Geolocation}
We can easily combine the two methods suggested above using the weighted least squares (WLS) method.
Using the calculated CRB for TDOA and FDOA, we can define the weight matrices $W_T$ and $W_F$ for the TDOA measurements and for the FDOA measurements respectively.
Then, the measurements can be combined in the following cost function:
\begin{equation}
C_{TF}(\vec{p},\vec{v}) = \sum_{i=1}^L \sum_{j=1}^L {W_T}_{i,j}(T(\vec{p})_{i,j}-\hat{T}_{i,j})^2+ {W_F}_{i,j}(F(\vec{p},\vec{v})_{i,j}-\hat{F}_{i,j})^2
\end{equation}

\section{DPD Algorithm Concepts}
In this section we introduce the main ideas and concepts behind the DPD algorithm \cite{dpd}.\\

Most common methods consist of two steps. The first step is to estimate a certain parameter of the
SOI, such as TDOA or FDOA. \\
The second step is to use the parameter estimated at each of the receivers, or receivers pairs, to estimate the location of the transmitter, usually using the least squares algorithm.\\
It is important to note that the estimation of the SOI parameters is done independently in each receiver or pair of receivers, so that the information used in each of the estimations is partial and consists only on the samples collected by its own antennas.\\
The DPD algorithm skips the first step of parameter estimation. All of the samples are collected at a central base station, and the location of the transmitter is estimated using all of the samples at once, without making any intermediate estimations.\\

The DPD algorithm advantages are mainly better performance over conventional methods using the same data-inputs, and conceptual simplicity. The DPD algorithm main drawbacks are its computational complexity and the need for high band-width communication between the receivers and the central processing station in order to transfer the entire sampled signals from the receivers to the processing station.\\

The original DPD algorithm\cite{dpd} has been developed in recent years, and is now related to a family of algorithms, each of which related to a different scenario.
While the original DPD algorithm assume a static scenario, in which both the transmitters and the receivers are stationary, other algorithms (\cite{dpd_nb},\cite{dop_dpd}) assume that the receivers are moving in known velocities, while the transmitter is stationary, and use similar concepts to determine the position of the transmitter.\\

In this work, we present a direct passive geolocation algorithm for a moving transmitter.

\section{Outline}

\chapter{Problem Formulation}

\section{General}
Consider $L$ stationary radio receivers and a moving transmitter. The receivers are synchronized in frequency and time. Let  $\vec{p_\ell}$ $l\in{\{1..L\}}$ denote the positions of the stationary receivers. Let $\vec{v}=(v_x,v_y)$, $\vec{p}=(x,y)$ denote the velocity and position of the moving transmitter respectively, as can be seen in figure (\ref{fig:geometry}).\\

The complex signal observed by the l-th receiver at time t:

\begin{equation}
\label{eq:r_lDef}
r_\ell(t)=b_\ell s(t-T_\ell )e^{j2\pi \tilde{f_\ell} t}+w_\ell(t),  0\leq t\leq T                                              
\end{equation}

Where $T$ is the observation time interval, $s(t)$ is the observed signal envelope, $b_\ell$ is an unknown complex path attenuation, $T_\ell \triangleq \frac{1}{c}\|\vec{p} -\vec{p_\ell}\|$ is the signal's delay where $c$ is the signal's propagation speed, $w_\ell (t)$ is a wide sense stationary additive white zero mean complex Gaussian noise with flat spectrum and $\tilde{f_\ell}$ is given by:\\

The frequency received at the $\ell$ - th receiver: 
\begin{equation}
\label{eq:f_lDef}
\tilde{f_\ell}\triangleq[f_c+\nu][1+\mu_\ell (\vec{p} ,\vec{v})]                 
\end{equation}

 The frequency shift caused by the Doppler Effect:
\begin{equation} 
\mu_\ell \triangleq -\frac{1}{c} \frac{\vec{v}(\vec{p}-\vec{p_\ell})}{\|\vec{p}-\vec{p_\ell}\|}                             
\end{equation}

Where  $f_c$ is the known nominal carrier frequency of the transmitted signal, and $\nu$ is the unknown transmitted frequency shift due to the source instability during the interception interval.
Since $\mu_\ell \ll 1$ and $\nu \ll f_c$, equation (\ref{eq:f_lDef}) can be approximated as $\tilde{f_\ell}\approx \nu+f_c [1+\mu_\ell (\vec{p},\vec{v})]$ where the term $\nu\mu_\ell (\vec{p},\vec{v})$, which is negligible with respect to all other terms, is omitted . Also, since $f_c$ Is known to the receivers, each receiver performs a down conversion of the intercepted signal by $f_c$ and (\ref{eq:f_lDef}) can be replaced by:
\begin{equation}
\label{eq:tildef_lapprox}
\tilde{f_\ell} \approx \nu+ f_\ell (\vec{p},\vec{v})                                                                      
\end{equation}
Where we defined the frequency shift caused by the Doppler effect $f_\ell$ as follows:
\begin{equation}
f_\ell(\vec{p},\vec{v}) \triangleq f_c \mu_\ell(\vec{p},\vec{v})
\end{equation}


\begin{figure}[h]
\label{fig:geometry}
\scalebox{0.4}[0.4]{
\includegraphics[0,0][690,543]{fig1.jpg}
}
\centering
\caption[Scenario Geometry]
{Scenario Geometry. $\vec{p}$ and $\vec{v}$ denote the transmitter's position and velocity respectively. 
$\vec{p_\ell}$ is the position of the $\ell$-th receiver. $d_\ell$ is the distance between the transmitter and the $\ell$-th receiver. $\Theta_\ell$ is the angle between the line connecting the transmitter and the $\ell$-th receiver and the $x$-axis. $\phi_\ell$ is the angle between the transmitter's velocity and the line connecting the transmitter and the $\ell$-th receiver}

\end{figure}

\section{Narrow-Band Time Domain Analysis}
In the proceeding section we analyse the narrow-band signal scenario.
In the narrow-band scenario we assume that the change rate of the envelope of the transmitted signal is sufficiently small, so that the signal envelopes seen in all of the receivers is identical.\\

The narrow-band scenario analysis is brought here because of its slight relative simplicity compared to the wide-band scenario, and because we use this formulation later in this work to derive lower complexity methods to solve the problem presented.\\

We start by introducing the assumptions and definitions of the narrow-band scenario and later introduce the ML estimator for the narrow-band scenario.

\subsection{Definitions}
We assume that the signal's bandwidth (change rate) is small compared to the inverse of the propagation time between the receivers. i.e. $B<c/d$, where $d$ is a typical distance between the receivers. We can then assume that the signal's envelope is similar at all of the spatially separated receivers, meaning: $s(t-T_\ell )\approx s(t)$.\\
 
The down converted signal is sampled at times $t_n=nT_s$ where $n\in\{0..N-1\}$ and $T_s =\frac{T}{N-1}$.
The signal at the interception interval is given as $r_\ell [n]=r_\ell (nT_s)$, and equation (\ref{eq:r_lDef}) can be written in a vector form as:
\begin{equation}
\mathbf{r_\ell}=b_\ell A_\ell C \mathbf{s} + \mathbf{w_\ell}
\end{equation}

Where:

\begin{equation}
A_\ell \triangleq diag\{1,e^{2 \pi j f_\ell  T_s},\dots,e^{2 \pi j f_\ell (N-1) T_s} \}                                                         
\end{equation}

\begin{equation}
C \triangleq diag \{1  ,e^{2 \pi j \nu T_s},\dots,e^{2 \pi j \nu (N-1) T_s }\}                                                         
\end{equation}

\begin{equation}
s[n] \triangleq s(nT_s)                                                                                                          
\end{equation}

\begin{equation}
w_\ell [n] \triangleq w_\ell (nT_s)                                                                                                       
\end{equation}

Note that $A_\ell$  is a function of the unknown emitter position and velocity while $C$ is a function of the unknown transmitted frequency.
Here we assume that the signal's envelope is the same in all of the receivers.

\subsection{ML Estimator}

The log-likelihood function of the observation vectors is given (up to an additive constant) by:
\begin{equation}
\label{eq:L_1def}
L_1 = -\frac{1}{\sigma{2}} \sum_{l=1}^{L} \|\mathbf{r_\ell} - b_\ell A_\ell C \mathbf{s}\|^2                                                             
\end{equation}

The path attenuation factors that maximize Eq. (\ref{eq:L_1def}) are given by:
\begin{equation}
\label{eq:b_lCalc}
b_\ell = [(A_\ell C \mathbf{s})^{H} A_\ell C \mathbf{s}]^{-1}(A_\ell C \mathbf{s})^{H} \mathbf{r_\ell} = (A_\ell C \mathbf{s})^{H} \mathbf{r_\ell}
\end{equation}
Where we assume, without loss of generality, that $\|s \|^{2}=1$ and use the special structure of $A_\ell$
and $C$.\\
Substitution of Eq. (\ref{eq:b_lCalc}) into Eq. (\ref{eq:L_1def}) yields:
\begin{equation}
\label{eq:L_1Def2}
L_1=-\frac{1}{\sigma^2} [\sum_{l=1}^{L}\|\mathbf{r_\ell}\|^2 -\|(A_\ell C \mathbf{s})^H \mathbf{r_\ell}\|^2]
\end{equation}

Since $r_\ell$ is independent of the parameters, then instead of maximizing Eq. (\ref{eq:L_1Def2}), we can now maximize:
\begin{equation}
\label{eq:L_2Def}
L_2=\sum_{l=1}^{L}\|(A_\ell C \mathbf{s})^H \mathbf{r_\ell}\|^2=\mathbf{u}^HQ\mathbf{u}
\end{equation}

Where:
\begin{equation}
\mathbf{u} \triangleq C \mathbf{s}
\end{equation}

\begin{equation}
Q \triangleq V V^H
\end{equation}

\begin{equation}
V \triangleq [A_1^H \mathbf{r_1},\dots,A_L^H \mathbf{r_L}]                                                        
\end{equation}

In order to maximize the cost function, $\mathbf{u}$ should be selected as the eigenvector corresponding to the largest eigenvalue of the matrix $Q$.
Therefore, the cost function $L_2$ reduces to
\begin{equation}
L_3= \lambda_{max} \{Q\}
\end{equation}
By using the known theorem that given a matrix $X$, the non zero eigenvalues of $XX^H$ and $X^H X$ are identical, we can replace the $N \times N$ matrix with an $L \times L$ matrix: 
\begin{equation}
\tilde{Q} \triangleq  V^H V 
\end{equation}

So that:

\begin{equation}
L_3= \lambda_{max} \{Q\} = \lambda_{max} \{\tilde{Q}\}
\end{equation}
And now we can go forward and perform a grid search in the $(\vec{p},\vec{v})$ space to maximize the cost function.

\section{Wide-Band Time Domain Analysis}
In the following section we introduce the analysis of the scenario in which the signal is wide-band. 
Although we do not make any further simplifying assumptions, the problem formulation and ML estimator derivation is similar to the narrow-band scenario.\\

We start by introducing the assumptions and definitions of the wide-band scenario, and later derive the ML estimator for the wide-band scenario.

\subsection{Definitions}
The down converted signal is sampled at times $t_n=nT_s$ where $n\in\{0..N-1\}$ and $T_s =\frac{T}{N-1}$.
The signal at the interception interval is given as $r_\ell [n]=r_\ell (nT_s)$, and equation (\ref{eq:r_lDef}) can be written in a vector form as:

\begin{equation}
\label{eq:r_lWBDef}
\mathbf{r_\ell}=b_\ell A_\ell F_\ell C \mathbf{s} + \mathbf{w_\ell}
\end{equation}

Where:
\begin{equation}
A_\ell \triangleq diag\{1,e^{2 \pi j f_\ell  T_s},\dots,e^{2 \pi j f_\ell (N-1) T_s} \}                                                         
\end{equation}

\begin{equation}
C \triangleq diag \{1  ,e^{2 \pi j \nu T_s},\dots,e^{2 \pi j \nu (N-1) T_s }\}                                                         
\end{equation}

\begin{equation}
s[n] \triangleq s(nT_s)                                                                                                           
\end{equation}

\begin{equation}
w_\ell[n] \triangleq w_\ell(nT_s)                                                                                                        
\end{equation}

$F_\ell$ is a downshift operator. The product $F_\ell$ shifts the vector $\mathbf{s}$ by $\lfloor ^{T_\ell}/_{T_s} \rfloor$ indices.
Note that $A_\ell$ is a function of the unknown emitter position and velocity, $F_\ell$ is a function of the unknown emitter position, while $C$ is a function of the unknown transmitted frequency.
 
\subsection{ML estimator}
The log-likelihood function of the observation vectors is given (up to an additive constant) by:
\begin{equation}
\label{eq:L_1WBdef}
L_1 = -\frac{1}{\sigma{2}} \sum_{l=1}^{L} \|\mathbf{r_\ell} - b_\ell A_\ell F_\ell C \mathbf{s}\|^2                                                             
\end{equation}

The path attenuation factors that maximize Eq. (\ref{eq:L_1WBdef}) are given by:
\begin{equation}
\label{eq:b_lWBdef}
b_\ell = [(A_\ell F_\ell C \mathbf{s})^{H} A_\ell F_\ell C \mathbf{s}]^{-1}(A_\ell F_\ell C \mathbf{s})^{H} \mathbf{r_\ell} = (A_\ell F_\ell C \mathbf{s})^{H} \mathbf{r_\ell}
\end{equation}

Where we assume, without loss of generality that $\|\mathbf{s}\|^2=1$ and use the special structure of $A_\ell$ and $C$.
Substitution of Eq. (\ref{eq:b_lWBdef}) into Eq. (\ref{eq:L_1WBdef}) yields:
\begin{equation}
\label{eq:L_1WBdef2}
L_1=-\frac{1}{\sigma^2} [\sum_{(l=1)}^{L}\|\mathbf{r_\ell}\|^2 -\|(A_\ell F_\ell C \mathbf{s})^H \mathbf{r_\ell}\|^2]
\end{equation}
Since $\mathbf{r_\ell}$ is independent of the parameters, then instead of maximizing Eq. (\ref{eq:L_1WBdef2}), we can now maximize:

\begin{equation}
\label{eq:L_2WBdef}
L_2=\sum_{(l=1)}^{L}\|(A_\ell F_\ell C \mathbf{s})^H \mathbf{r_\ell}\|^2 = \mathbf{u}^HQ\mathbf{u}f
\end{equation}

Where:

\begin{equation}
u \triangleq C \mathbf{s}
\end{equation}

\begin{equation}
Q \triangleq V V^H
\end{equation}


\begin{equation}
V \triangleq [F_1^H A_1^H \mathbf{r_1},\dots ,F_L^H A_L^H \mathbf{r_L}]                                                        
\end{equation}

In order to maximize the cost function, $u$ should be selected as the eigenvector corresponding to the largest eigenvalue of the matrix $Q$.
Therefore, the cost function $L_2$ reduces to

\begin{equation}
L_3=\lambda_{max}\{Q\}
\end{equation}

By using the known theorem that given a matrix $X$, the non zero eigenvalues of $XX^H$ and $X^H X$ are identical, we can replace the $N \times N$ matrix with an $L \times L$ matrix. 

\begin{equation}
\tilde{Q}  \triangleq V^H V                                                                               
\end{equation}

So that:
\begin{equation}
L_3=\lambda_{max}\{Q\} = \lambda_{max}\{\tilde{Q}\} 
\end{equation}

And now we can go forward and perform a grid search in the $(\vec{p},\vec{v})$ space to maximize the cost function.

\chapter{Exploring the cost function $L_2$}
In this section, we will try to analyse the cost function $L_2$, in order to get
some insight about its behaviour.
Because $L_2$ requires the knowledge of the transmitted signal, it is mainly useful for
the case in which the transmitted signal is known.
\\
It is important to remember that given a received signal, $L_2$ is a function
of the evaluated transmitter's position and velocity estimates, meaning $L_2(\vec{p},\vec{v})$.
The dependency of the cost function in these parameters is expressed by $A_\ell$ that depends
on the relative speed and position between the transmitter and the receiver, and by $F_\ell$ that depends
on the relative distance between the transmitter and the receiver.

\section{Zero Noise Analysis - Simplified Scenario}

In order to simplify the analysis, we will use a few assumptions in the proceeding subsection.
We will assume that $b_\ell=1$ $\forall l\in\{1\dots L\}$, that there is no source instability, meaning $\nu=0$ so that $C=I$,and that the signal is narrow-band, meaning $F_\ell=I$ $\forall l\in\{1\dots L\}$.

Remember that $$\mathbf{r_\ell}=b_\ell A_\ell F_\ell C \mathbf{s} + \mathbf{w_\ell}$$
We can write:
\begin{equation}
\mathbf{r_\ell}= A^{(0)}_\ell \mathbf{s}
\end{equation}
where we used the assumptions that $b_\ell=1$, $C=I$, $F_\ell=I$, $\mathbf{w}_\ell=0$. $A^{(0)}_\ell$, represents the
true Doppler frequency shift caused by the relative speed of the transmitter and the emitters.

Thus:

\begin{equation}
\label{eq:simplifiedanalysis1}
(A_\ell\mathbf{s})^H\mathbf{r_\ell}=(A_\ell\mathbf{s})^H(A^{(0)}_\ell \mathbf{s})
\end{equation}

Therefore:

\begin{equation}
\|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2=\|(A_\ell\mathbf{s})^H(A^{(0)}_\ell \mathbf{s})\|^2=\|\mathbf{s}^H A_\ell^H A^{(0)}_\ell \mathbf{s}\|^2
\end{equation}

Defining:
\begin{equation}
D_\ell = A_\ell^H A^{(0)}_\ell
\end{equation}
Where $D_\ell$ is a frequency shift operator, shifting the signal by $f^{(0)}_\ell-f_\ell$ where $f^{(0)}_\ell$ is
the true Doppler shift of the signal received by the $\ell$-th receiver.
We can see that:

\begin{equation}
\|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2 = \|\mathbf{s}^H D_\ell \mathbf{s}\|^2
\end{equation}
Which is the squared absolute value of the correlation between the signal shifted by $f^{(0)}_\ell-f_\ell$ and the original signal.


\begin{equation}
L_2 = \sum_{l=1}^L \|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2 = \sum_{l=1}^L \|\mathbf{s}^H D_\ell \mathbf{s}\|^2
\end{equation}
Which is the sum of squared absolute value of the correlation between the signal shifted by $f^{(0)}_\ell-f_\ell$ and the original signal.
We can easily see that the maximum of the simplified $L_2$ function will occur when 
$\forall l \in \{1 \dots L \}$, $\mathbf{D_\ell}=I$, meaning that $\forall l \in \{1 \dots L \}$, 
$f_\ell = f^{(0)}_\ell$.
Notice that if the location of the receivers is known with infinite accuracy, the maximum
of the simplified cost function $L_2$ occurs at the true position of the transmitter.\\
If the there is an error in the known position of the receivers, there is no transmitter position and velocity ($\vec{p}, \vec{v}$) for which $\forall l \in\{1\dots L\}$, $\mathbf{D_\ell}(\vec{p},\vec{v}) = I$ and there is no guarantee that the maximum of the cost function occurs at the true transmitter position.
\\
We can notice that for the simplified scenario $\mathbf{D_\ell}(\vec{p},\vec{v})$ is actually a function of
$(\|\vec{v}\|cos\phi_\ell)$, and it can be written as $\mathbf{D_\ell}(\|\vec{v}\|cos\phi_\ell)$.

\section{Noisy Analysis - Simplified Scenario}
In this subsection we will try to analyse the effect of the noise in the receiver on the
cost function.
\\
If we consider the noise, (\ref{eq:simplifiedanalysis1}) becomes:
\begin{equation}
(A_\ell\mathbf{s})^H\mathbf{r_\ell}=(A_\ell\mathbf{s})^H(A^{(0)}_\ell \mathbf{s}+\mathbf{w_\ell})=\mathbf{s}^H D_\ell \mathbf{s}+ \mathbf{s}^H A_\ell \mathbf{w_\ell}
\end{equation}
So:
\begin{eqnarray}
L_2^{(\ell)}= \\
&=& \|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2 = \nonumber\\ 
&=&\|\mathbf{s}^H D_\ell \mathbf{s}\|^2+\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2 + \mathbf{s}^H D_\ell \mathbf{s}(\mathbf{s}^H A_\ell \mathbf{w_\ell})^H + \mathbf{s}^H A_\ell \mathbf{w_\ell}(\mathbf{s}^H D_\ell \mathbf{s})^H = 
\nonumber \\ 
&=& \|\mathbf{s}^H D_\ell \mathbf{s}\|^2+\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2 + \mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s} + \mathbf{s}^H A_\ell \mathbf{w_\ell}\mathbf{s}^H D_\ell^H \mathbf{s} \nonumber
\end{eqnarray}
Because $\mathbf{w_\ell}$ is stochastic, $L_2$ is also a stochastic variable and we can look at its
stochastic properties such as expectation and variance.
\begin{eqnarray}
\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2 = \\
&=& \| \sum_{m=1}^N{s[m]^H a_\ell[m] w_\ell[m]}\|^2 = \nonumber \\
&=&\sum_{m=1}^N\sum_{n=1}^N s[m]^H s[n] a_\ell[m] a_\ell^H[n] w_\ell[m] w_\ell^H[n] \nonumber
\end{eqnarray}

\begin{eqnarray}
E\{\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2\}= \\
&=& E\left\{\sum_{m=1}^N\sum_{n=1}^N s[m]^H s[n] a_\ell[m] a_\ell^H[n] w_\ell[m] w_\ell^H[n]\right\}= \nonumber \\
&=& \sum_{m=1}^N \sigma_\ell^2 |a_\ell[m]|^2 |s[m]|^2 = \nonumber \\
&=& \sigma_\ell^2 \|\mathbf{s}\|^2 \nonumber
\end{eqnarray}

\begin{equation}
E\{L_2^{(\ell)}\}=E\{\|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2\}= \|\mathbf{s}^H D_\ell \mathbf{s}\|^2 + \sigma_\ell^2\|\mathbf{s}\|^2
\end{equation}
Where we used the assumptions that $\mathbf{w_\ell}$ is a zero mean, i.i.d process with $\sigma_\ell^2$ variance.
Thus:
\begin{equation}
E\{L_2\}=\sum_{l=1}^L E\{\|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2\}= \|\mathbf{s}^H D_\ell \mathbf{s}\|^2 + \sigma_\ell^2\|\mathbf{s}\|^2
\end{equation}

\begin{eqnarray}
\label{eq:var_l_2_l_simplified}
VAR\{L_2^{(\ell)}\} = \\
&=&VAR\{ \mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s} + \mathbf{s}^H A_\ell \mathbf{w_\ell}\mathbf{s}^H D_\ell^H \mathbf{s}\} = \nonumber\\
&=&2E\{\| \mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s} \|^2 \} + 2RE \{E\{(\mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s})^2 \}\} =  \nonumber \\
&=&2\| \mathbf{s}^H D_\ell \mathbf{s}\|^2\sigma_\ell^2\|\mathbf{s}\|^2 +2 RE \left\{(\mathbf{s}^H D_\ell \mathbf{s})^2 E\left\{(\mathbf{w_\ell}^H A_\ell^H \mathbf{s})^2\right\}\right\} \nonumber
\end{eqnarray}

If we notice that for an arbitary complex Gaussian variable $a+bj$:
\begin{eqnarray*}
E\{(a+jb)^2\} = \\
&=& E\{a^2-b^2+2abj \}= E\{a^2\}-E\{b^2\} +2jE\{ab\}= \\
&=& \sigma^2-\sigma^2+0 = 0
\end{eqnarray*}
Where we assumed that $VAR\{a\} = VAR \{b\} = \sigma^2$ and that $a$ and $b$ have zero mean and are uncorrelated.\\
We can see that $E\left\{(\mathbf{w_\ell}^H A_\ell^H \mathbf{s})^2\right\}=0$  and (\ref{eq:var_l_2_l_simplified})
becomes:
\begin{equation}
VAR\{L_2^{(\ell)}\} =2\| \mathbf{s}^H D_\ell \mathbf{s}\|^2\sigma_\ell^2\|\mathbf{s}\|^2 
\end{equation}
Thus:
\begin{equation}
VAR\{L_2\} = \sum_{l=1}^L 2\| \mathbf{s}^H D_\ell \mathbf{s}\|^2\sigma_\ell^2\|\mathbf{s}\|^2 
\end{equation}

\section{Zero Noise Analysis}

In the proceeding section we will not use the assumptions used above, in the simplified scenario sections.
We will express $L_2$ using the complete signal model presented.

Remembering that:
 $$\mathbf{r_\ell}=b_\ell A_\ell F_\ell C \mathbf{s} + \mathbf{w_\ell}$$ 
 
 We can write:
\begin{equation}
\mathbf{r_\ell}= b_\ell A_\ell^{(0)} F_\ell^{(0)} C^{(0)} \mathbf{s}
\end{equation}
Where we used the assumption that $\mathbf{w}_\ell=0$. 
\\ \\
$A^{(0)}_\ell$, $F_\ell^{(0)}$, $C^{(0)}$ represent the true Doppler frequency shift caused by the relative speed of the transmitter and the receivers, the true delay caused by the relative distance of the transmitter and the receivers and the true transmitter frequency instability respectively.

Thus:

\begin{equation}
\label{eq:analysis1}
(A_\ell F_\ell C \mathbf{s})^H\mathbf{r_\ell}=(A_\ell F_\ell C\mathbf{s})^H(b_\ell A_\ell^{(0)} F_\ell^{(0)} C^{(0)} \mathbf{s})
\end{equation}

Therefore:

\begin{eqnarray}
\|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2 =\\
&=&\|(A_\ell F_\ell C\mathbf{s})^H(b_\ell A_\ell^{(0)} F_\ell^{(0)} C^{(0)} \mathbf{s})\|^2= \nonumber \\
&=&\|\mathbf{s}^H C^H F_\ell^H A_\ell^H b_\ell A_\ell^{(0)} F_\ell^{(0)} C^{(0)} \mathbf{s}\|^2 \nonumber
\end{eqnarray}

Defining:
\begin{equation}
D_\ell \triangleq  F_\ell^H  F_\ell^{(0)} A_\ell^H A^{(0)}_\ell C^H C^{(0)}
\end{equation}

Where $D_\ell$ is a frequency and time shift operator, shifting the signal frequency by $(f^{(0)}_\ell-f_\ell)+(\nu^{(0)}-\nu)$ and shifting the signal by $\lfloor ^{T_\ell^{(0)}}/_{T_s} \rfloor- \lfloor ^{T_\ell}/_{T_s} \rfloor$ indices. $f^{(0)}_\ell$ is the true Doppler shift of the signal received by the $\ell$-th receiver, $\nu^{(0)}$ is the true frequency instability of the transmitter and $T_\ell^{(0)}$ is the delay caused by the true distance between the transmitter and the $\ell$-the receiver.
\\
If we notice that if $A$ is a general frequency-shift matrix, $F$ is a general time shift
operator and $\mathbf{s}$ is an arbitrary signal, then $\|AF\mathbf{s}\|^2=\|FA\mathbf{s}\|^2$,
then we can write:

\begin{equation}
\|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2 = \|b_\ell\|^2\|\mathbf{s}^H D_\ell \mathbf{s}\|^2
\end{equation}

We can see that the expression above is the correlation between the signal shifted by $\lfloor ^{T_\ell^{(0)}}/_{T_s} \rfloor- \lfloor ^{T_\ell}/_{T_s} \rfloor$ indices and by $(f^{(0)}_\ell-f_\ell)+(\nu^{(0)}-\nu)$ in frequency and the original signal.

And eventually:
\begin{equation}
L_2 = \sum_{l=1}^L \|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2 = \sum_{l=1}^L \|\mathbf{s}^H D_\ell \mathbf{s}\|^2
\end{equation}
Which is the sum of squared absolute value of the correlation between the time and frequency shifted signal and the original signal.

\section{Noisy Analysis}
In this subsection we will try to analyse the effect of the noise in the receiver on the
cost function.
\\
If we consider the noise, (\ref{eq:analysis1}) becomes:
\begin{equation}
(A_\ell\mathbf{s})^H\mathbf{r_\ell}=(A_\ell\mathbf{s})^H(A^{(0)}_\ell \mathbf{s}+\mathbf{w_\ell})=\mathbf{s}^H D_\ell \mathbf{s}+ \mathbf{s}^H A_\ell \mathbf{w_\ell}
\end{equation}
So:
\begin{eqnarray}
L_2^{(\ell)}= \\
&=& \|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2 = \nonumber\\ 
&=&\|\mathbf{s}^H D_\ell \mathbf{s}\|^2+\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2 + \mathbf{s}^H D_\ell \mathbf{s}(\mathbf{s}^H A_\ell \mathbf{w_\ell})^H + \mathbf{s}^H A_\ell \mathbf{w_\ell}(\mathbf{s}^H D_\ell \mathbf{s})^H = 
\nonumber \\ 
&=& \|\mathbf{s}^H D_\ell \mathbf{s}\|^2+\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2 + \mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s} + \mathbf{s}^H A_\ell \mathbf{w_\ell}\mathbf{s}^H D_\ell^H \mathbf{s} \nonumber
\end{eqnarray}
Because $\mathbf{w_\ell}$ is stochastic, $L_2$ is also a stochastic variable and we can look at its
stochastic properties such as expectation and variance.
\begin{eqnarray}
\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2 = \\
&=& \| \sum_{m=1}^N{s[m]^H a_\ell[m] w_\ell[m]}\|^2 = \nonumber \\
&=&\sum_{m=1}^N\sum_{n=1}^N s[m]^H s[n] a_\ell[m] a_\ell^H[n] w_\ell[m] w_\ell^H[n] \nonumber
\end{eqnarray}

\begin{eqnarray}
E\{\|\mathbf{s}^H A_\ell \mathbf{w_\ell}\|^2\}= \\
&=& E\left\{\sum_{m=1}^N\sum_{n=1}^N s[m]^H s[n] a_\ell[m] a_\ell^H[n] w_\ell[m] w_\ell^H[n]\right\}= \nonumber \\
&=& \sum_{m=1}^N \sigma_\ell^2 |a_\ell[m]|^2 |s[m]|^2 = \nonumber \\
&=& \sigma_\ell^2 \|\mathbf{s}\|^2 \nonumber
\end{eqnarray}

\begin{equation}
E\{L_2^{(\ell)}\}=E\{\|(A_\ell\mathbf{s})^H\mathbf{r_\ell}\|^2\}= \|\mathbf{s}^H D_\ell \mathbf{s}\|^2 + \sigma_\ell^2\|\mathbf{s}\|^2
\end{equation}
Where we used the assumptions that $\mathbf{w_\ell}$ is a zero mean, i.i.d process with $\sigma_\ell^2$ variance.

\begin{eqnarray}
VAR\{L_2^{(\ell)}\} = \\
&=&VAR\{ \mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s} + \mathbf{s}^H A_\ell \mathbf{w_\ell}\mathbf{s}^H D_\ell^H \mathbf{s}\} = \nonumber\\
&=&2E\{\| \mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s} \|^2 \} + 2RE \{E\{(\mathbf{s}^H D_\ell \mathbf{s}\mathbf{w_\ell}^H A_\ell^H \mathbf{s})^2 \}\} =  \nonumber \\
&=&2\| \mathbf{s}^H D_\ell \mathbf{s}\|^2\sigma_\ell^2\|\mathbf{s}\|^2 \nonumber
\end{eqnarray}

Thus:
\begin{equation}
VAR\{L_2\} = \sum_{l=1}^L 2\| \mathbf{s}^H D_\ell \mathbf{s}\|^2\sigma_\ell^2\|\mathbf{s}\|^2
\end{equation}


\section{Expression For $\frac{\partial L_2}{\partial v_x}$ and $\frac{\partial L_2}{\partial v_y}$}
\label{d_L2_dvx_d_vy}
Defining:
\begin{equation}
L_2^{(\ell)} \triangleq \|\left(A_\ell F_\ell C \mathbf{s} \right)^H\mathbf{r_\ell}\|^2
\end{equation}
The cost function $L_2$ can be expressed as:
\begin{equation}
L_2 = \sum_{l=1}^L L_2^{(\ell)}
\end{equation}
For further simplicity along the derivation we will define:
\begin{equation}
\mathbf{u_\ell} \triangleq F_\ell C \mathbf{s}
\end{equation}
So $L_2^{(\ell)}$ is expressed as:
\begin{equation}
L_2^{(\ell)} = \|( A_\ell \mathbf{u_\ell})^H\mathbf{r_\ell}\|^2
\end{equation}

Notice that for an arbitrary vector $\mathbf{x}$, if $y=\|\mathbf{x}\|^2=\mathbf{x}^H\mathbf{x}$ then
$$ \frac{\partial y}{\partial z} = \frac{\partial \mathbf{x}}{\partial z}^H\mathbf{x}+ \mathbf{x}^H\frac{\partial \mathbf{x}}{\partial z}=2RE\left\{ \frac{\partial \mathbf{x}}{\partial z}^H\mathbf{x} \right\} $$

Using the above statement:
\begin{equation}
\frac{\partial}{\partial v_x} L_2^{(\ell)}  = 2 RE
\left\{ 
\left[\frac{\partial}{\partial v_x} (Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right]^H(Al \mathbf{u_\ell})^H \mathbf{r_\ell}
\right\}
\end{equation}

\begin{equation}
\label{eq:da_l_d_v_x}
\frac{\partial}{\partial v_x}\left( (Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right) = \frac{\partial}{\partial f_\ell}\left( (Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right) \frac{\partial f_\ell}{\partial v_x}
\end{equation}

\begin{eqnarray}
\frac{\partial}{\partial f_\ell}\left( (Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right) = \\
&=& \frac{\partial}{\partial f_\ell} \left(
\sum_{n=0}^{N-1}e^{-2 \pi k f_\ell T_s n}u_\ell^*[n]r_\ell[n]
\right) = \nonumber\\
&=& -2 \pi j T_s \sum_{n=0}^{N-1}ne^{-2 \pi k f_\ell T_s n}u_\ell^*[n]r_\ell[n] = 
\nonumber\\
&=& -2 \pi j T_s \left( (\tilde{N} Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right) \nonumber
\end{eqnarray}

Where we used the matrix $ \tilde{N}$ defined:
\begin{equation}
\tilde{N} \triangleq diag\{0,1,\dots ,N-1\}
\end{equation}

Therefore:
\begin{equation}
\left[\frac{\partial}{\partial v_x} (Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right]^H = -2 \pi j T_s \frac{f_c}{c}cos\theta_\ell\mathbf{r_\ell}^H(\tilde{N} A_\ell \mathbf{u_\ell})
\end{equation}
Hence:
\begin{equation}
\frac{\partial L_2}{\partial v_x} = \sum_{l=1}^L (4 \pi T_s\frac{f_c}{c} cos\theta_\ell) IM
\left\{
(A_\ell \mathbf{u_\ell})^H \mathbf{r_\ell}\mathbf{r_\ell}^H (\tilde{N}A_\ell\mathbf{u_\ell})
\right\}
\end{equation}

And after substituting $\mathbf{u_\ell}$:
\begin{equation}
\label{eq:d_l_2_d_v_x_final}
\frac{\partial L_2}{\partial v_x} = \sum_{l=1}^L (4 \pi T_s\frac{f_c}{c} cos\theta_\ell) IM
\left\{
(A_\ell F_\ell C \mathbf{s})^H \mathbf{r_\ell}\mathbf{r_\ell}^H (\tilde{N}A_\ell F_\ell C \mathbf{s})
\right\}
\end{equation}

And similarly:
\begin{equation}
\label{eq:d_l_2_d_v_y_final}
\frac{\partial L_2}{\partial v_y} = \sum_{l=1}^L (4 \pi T_s\frac{f_c}{c} sin\theta_\ell) IM
\left\{
(A_\ell F_\ell C \mathbf{s})^H \mathbf{r_\ell}\mathbf{r_\ell}^H (\tilde{N}A_\ell F_\ell C \mathbf{s})
\right\}
\end{equation}

To demonstrate that the expressions above give the exact location when there is no noise,
we will take $F_\ell=I$ (narrow-band case, for ease), $\mathbf{r_\ell} = A_\ell^{(0)} C^{(0)} \mathbf{s}$
and $C=C^{(0)}$, $A_\ell = A_\ell^{(0)}$.


\begin{equation}
(A_\ell F_\ell C \mathbf{s})^H \mathbf{r_\ell} = \mathbf{s}^H C^{(0)H} A_\ell^{(0)H} A_\ell^{(0)} C^{(0)} \mathbf{s} = 
\|\mathbf{s}\|^2
\end{equation}

\begin{equation}
\mathbf{r_\ell}^H (\tilde{N}A_\ell F_\ell C \mathbf{s}) = 
\mathbf{s}^H C^{(0)H} A_\ell^{(0)H} \tilde{N} A_\ell^{(0)} C^{(0)} \mathbf{s} = 
\mathbf{s}^H  \tilde{N} \mathbf{s} = \sum_{n=1}^Nn\|s[n]\|^2
\end{equation}
We can clearly see that the above expressions are real. Therefore, Substituting in (\ref{eq:d_l_2_d_v_x_final}) and in (\ref{eq:d_l_2_d_v_y_final}) we can see that $\vec{p_0},\vec{v_0}$
is an extremum point:
\begin{eqnarray}
\frac{\partial L_2}{\partial v_x}|_{\vec{p_0},\vec{v_0}} = 0 \\
\frac{\partial L_2}{\partial v_y}|_{\vec{p_0},\vec{v_0}}= 0 \nonumber
\end{eqnarray}

We can also easily show that the derivative of the cost function zeros when $F_\ell \neq I$ because the
above expressions are also real.

\section{Expression For $\frac{\partial L_2}{\partial x}$ and $\frac{\partial L_2}{\partial y}$ for Narrow-Band signals}
\label{d_L2_dx_d_y_NB}

For narrow-band signals, we assume that $F_\ell = I$, thus similarly to (\ref{eq:da_l_d_v_x}) we get:
\begin{equation}
\frac{\partial}{\partial x}\left( (Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right) = \frac{\partial}{\partial f_\ell}\left( (Al \mathbf{u_\ell})^H \mathbf{r_\ell}\right) \frac{\partial f_\ell}{\partial x}
\end{equation}

Using the results of the above section we get:

\begin{equation}
\frac{\partial}{\partial x}((A_\ell \mathbf{u_\ell})^H \mathbf{r_\ell}) = - 2 \pi j T_s ((\tilde{N} A_\ell \mathbf{u_\ell})^H\mathbf{r_\ell})\frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell} \sin \phi_\ell \sin \theta_\ell
\end{equation}

Therefore:

\begin{equation}
\frac{\partial L_2}{\partial x} = -\sum_{l=1}^L (4 \pi T_s \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell}\sin \phi_\ell \sin \theta_\ell ) \Im
\left\{
(A_\ell C \mathbf{s_\ell})^H \mathbf{r_\ell}\mathbf{r_\ell}^H (\tilde{N}A_\ell C \mathbf{s_\ell})
\right\}
\end{equation}

And similarly:
\begin{equation}
\frac{\partial L_2}{\partial y} = \sum_{l=1}^L (4 \pi T_s \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell}\sin \phi_\ell \cos \theta_\ell ) \Im
\left\{
(A_\ell C \mathbf{s_\ell})^H \mathbf{r_\ell}\mathbf{r_\ell}^H (\tilde{N}A_\ell C \mathbf{s_\ell})
\right\}
\end{equation}
To demonstrate that when there is no noise, there is an extremum point in the true position of the transmitter, we can see that the expression inside the $\Im\{\dots\}$ operator is identical to the one in the expression for $\frac{\partial L_2}{\partial v_x}$. So, for the true position of the transmitter, the
expression inside the $\Im\{\dots\}$ operator is real, and we get:
\begin{eqnarray}
\frac{\partial L_2}{\partial x}|_{\vec{p_0},\vec{v_0}} = 0 \\
\frac{\partial L_2}{\partial y}|_{\vec{p_0},\vec{v_0}}= 0 \nonumber
\end{eqnarray}

\section{Expression For $\frac{\partial L_2}{\partial x}$ and $\frac{\partial L_2}{\partial y}$ for Wide-Band signals}
\label{d_L2_dx_dy_WB}
In order to derive an expression for $\frac{\partial L_2}{\partial x}$ and $\frac{\partial L_2}{\partial y}$ for wide-band signals, we can relate to $F_\ell$ as a continuous time-shift operator.
We can write:
\begin{equation}
L_2^{(\ell)}=\|(A_\ell F_\ell C\mathbf{s})^H\mathbf{r_\ell}\|^2 = \|(A_\ell C F_\ell \mathbf{s})^H\mathbf{r_\ell}\|^2= \|(A_\ell C \mathbf{s_\ell})^H\mathbf{r_\ell}\|^2
\end{equation}

Where we denote:
\begin{equation}
\mathbf{s_\ell} \triangleq [s(t_1-T_\ell) \dots s(t_N-T_\ell)]^T                                                           
\end{equation}

We know that:
\begin{equation}
\frac{\partial L_2}{\partial x} = \sum_{l=1}^L \frac{\partial L_2^{(\ell)}}{\partial x}=\sum_{l=1}^L \frac{\partial L_2^{(\ell)}}{\partial T_\ell}\frac{\partial T_\ell}{\partial x}+\frac{\partial L_2^{(\ell)}}{\partial f_\ell}\frac{\partial f_\ell}{\partial x}
\end{equation}

And:

\begin{equation}
\frac{\partial L_2^{(\ell)}}{\partial T_\ell} = \frac{\partial}{\partial T_\ell} \|(A_\ell C \mathbf{s_\ell})^H\mathbf{r_\ell}\|^2
\end{equation}

We notice that:
\begin{equation}
\frac{\partial}{\partial T_\ell} (Al C \mathbf{s_\ell})^H \mathbf{r_\ell} = - (Al C \mathbf{\dot{s_\ell}})^H \mathbf{r_\ell}
\end{equation}

Thus:
\begin{eqnarray}
\frac{\partial L_2^{(\ell)}}{\partial T_\ell} = \\
&=& 2 \Re \{(- (Al C \mathbf{\dot{s_\ell}})^H \mathbf{r_\ell})^H (Al C \mathbf{s_\ell})^H \mathbf{r_\ell} \} \nonumber\\
&=& -2 \Re \{(Al C \mathbf{s_\ell})^H \mathbf{r_\ell} \mathbf{r_\ell}^H (A_\ell C \mathbf{\dot{s_\ell}})\} \nonumber
\end{eqnarray}

Subtituting we get:
\begin{eqnarray}
\frac{\partial L_2}{\partial x} = \\
&=& \sum_{l=1}^L -2 \Re \left\{ (A_\ell C \mathbf{s_\ell})^H \mathbf{r_\ell} \mathbf{r_\ell}^H (A_\ell C \mathbf{\dot{s_\ell}})\right\}\frac{1}{c}\cos\theta_\ell - \nonumber \\
&-& 4\pi T_s \frac{F_c}{c} \frac{\|\vec{v}\|}{d_\ell} \sin \phi_\ell \sin \theta_\ell \Im \left\{ (A_\ell C  \mathbf{s_\ell})^H \mathbf{r_\ell} \mathbf{r_\ell}^H (\tilde{N} A_\ell C \mathbf{s_\ell})\right\} \nonumber
\end{eqnarray}

And similarly for $\frac{\partial L_2}{\partial y}$:
\begin{eqnarray}
\frac{\partial L_2}{\partial y} = \\
&=& \sum_{l=1}^L -2 \Re \left\{ (A_\ell C \mathbf{s_\ell})^H \mathbf{r_\ell} \mathbf{r_\ell}^H (A_\ell C \mathbf{\dot{s_\ell}})\right\}\frac{1}{c}\sin\theta_\ell + \nonumber \\
&+& 4\pi T_s \frac{F_c}{c} \frac{\|\vec{v}\|}{d_\ell} \sin \phi_\ell \cos \theta_\ell \Im \left\{ (A_\ell C  \mathbf{s_\ell})^H \mathbf{r_\ell} \mathbf{r_\ell}^H (\tilde{N} A_\ell C \mathbf{s_\ell})\right\} \nonumber
\end{eqnarray}

\section{Performance Analysis for Known Narrow Band Signals}
From \
...we get the expression for the error covariance:
\begin{equation}
E\{\Delta \mathbf{x}\Delta \mathbf{x}^T\}=
 -\left[\frac{\partial^2F}{\partial \mathbf{x}^2}\right]^{-1} 
 \left[ \frac{\partial^2 F}{\partial \mathbf{x} \partial \mathbf{a}} \right]
 E\{\Delta \mathbf{a}\Delta \mathbf{a}^T\}
  \left[ \frac{\partial^2 F}{\partial \mathbf{x} \partial \mathbf{a}} \right]^T
  \left[\frac{\partial^2F}{\partial \mathbf{x}^2}\right]^{-T} 
\end{equation}
Where in our case:
\begin{eqnarray}
F=L_2 \\
\mathbf{x} = \begin{pmatrix} x\\y\\v_x\\v_y\end{pmatrix} \nonumber \\
\mathbf{a} = [\mathbf{w_1}^T, \dots ,\mathbf{w_\ell}^T, \nu, p_{1,x}, p_{1,y}, \dots, p_{L,x}, p_{L,y}]^T \nonumber
\end{eqnarray}
\chapter{Exploring the cost function $L_3$}
\chapter{Location Algorithms}
\section{General}
The aim of this study is to develop a localization method for moving RF transmitters that
will have superior performance without significantly raising the algorithm complexity.\\
While conventional algorithms estimate the TDOA and FDOA parameters from which they obtain the transmitter
location, the suggested algorithm finds the location and velocity directly, without intermediate estimations
and by applying a search that involves the complete data gathered from all of the base stations simultaneously. \\
In this sense, it is an extension of the DPD algorithm, that was developed for the static transmitter and moving receivers scenario.\\
 The proposed method performs localization of a moving RF transmitter and an estimation
of its velocity.\\
The unknown velocity adds to the unknown parameters of the problem, thus, increasing its
complexity. Applying the conventional grid-search method requires a 4-dimensional grid-search for every
estimation, drastically increasing the complexity.\\

In the following sections, we will suggest algorithms for
different scenarios, allowing to reduce the problem's complexity using gradient based methods, in the cases
in which it was possible to differentiate the cost function.\\
The scenarios for which we will be able to reduce complexity are mainly the scenarios in which
the signals are known. We employ our knowledge on the cost function $L_2$ and its
derivatives in order to perform gradient based methods in the position and velocity space to find the maximum of the cost function.\\
In the scenario where the signal is both known and narrow band, we are able to easily preform gradient based
methods in the position sub-space, in addition to the velocity sub-space.
In all of the gradient based methods we will assume that the function is convex in the search area.
The cost function is generally not convex, it is only approximately convex in a small area around its maximum.\\
Therefore, in each of the suggested algorithms employing gradient-based methods we will have to assume that
the start point for the algorithm is close enough to the maximum, so that it is found within the global maximum's convex area so that the algorithm is guaranteed to find the global maximum.
At the last section of the chapter, we will try to handle the dynamic scenario where the transmitter's
position is estimated in a number of lags along its trajectory. For this purpose we employ a simple
dynamic model for the transmitter and use an extended Kalman filter for the dynamic estimation.

\section{Known Narrow Band Signals}
In the case where the signals are known and are narrow-band, we can use our knowledge of
$L_2$ and its derivatives to perform gradient-based methods to avoid performing a grid-search.
Of course, to employ the gradient-based methods we need a good initial guess on the position and
velocity of the transmitter, which can be acquired by a rough initial grid-search, or, as we will later see
in section (\ref{applying_kalman}), from the prediction of the Kalman filter.\\

\subsection{Steepest Descent Method}
A simple implementation of gradient based steepest descent search can be employed using the results of sections  (\ref{d_L2_dvx_d_vy}) and (\ref{d_L2_dx_d_y_NB}). 
A starting point $$\mathbf{x}^{(0)}=[x^{(0)}, y^{(0)}, v_x^{(0)}, v_y^{(0)}]^T$$ has to be chosen using an initial guess, a-priori information about the location and velocity of the transmitter or using a rough grid-search.
At the $k$-th step we can choose: 
\begin{equation}
\mathbf{x}^{k+1}=\mathbf{x}^{k}+\alpha \nabla L_2 |_{\mathbf{x}^k}
\end{equation}

Where:
\begin{equation}
 \nabla L_2  = [\frac{\partial L_2}{x},\frac{\partial L_2}{y},\frac{\partial L_2}{v_x},\frac{\partial L_2}{v_y}]^T 
\end{equation}

We represent the stepsize with $\alpha$. There are many methods to determine the optimal stepsize, and usually there is a trade-off between optimality and complexity. The simplest choice is the constant stepsize. However, choosing a constant stepsize should be done carefully. If the stepsize is too large, divergence will occur, if the stepsize is too small, the rate of convergence may be very slow. Other common methods are the minimization rule, the Armijo rule, the Goldstein rule and the diminishing stepsize method. \\
The steepest descent search is very simple to derive and implement, but often leads to slow convergence rates.\\

\subsection{Gauss-Newton Method}
In order to achieve higher convergence rates, we can employ the Gauss-Newton method, described in \cite{gauss_newton_method}, trying to minimize the least squares cost $\frac{1}{2}\|g(\mathbf{x})\|^2$. 
Small adjustments need to be made in order to use the method to effectively find a maximum of the above cost function, rather than its minimum.
We define $\mathbf{x}$ as the unknown parameters vector:

\begin{equation*}
\mathbf{x} \triangleq \left[ x,y,v_x,v_y \right]^T
\end{equation*}

And therefore:
\begin{equation*}
\nabla \triangleq \left[\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial v_x},
\frac{\partial}{\partial v_y}\right]
\end{equation*}
If we use the notation in (\ref{eq:L_2Def}) we can choose:
$g(\mathbf{x})=\sqrt{2} \begin{pmatrix} Re\{V^H \mathbf{u}\} \\Im\{V^H \mathbf{u}\} \end{pmatrix}$ \\
notice that $\mathbf{u}$ is the known transmitted signal.
we get:
\begin{equation}
\frac{1}{2}\|g(\mathbf{x})\|^2=\|\Re\{V^H \mathbf{u}\}\|^2+\|\Im\{V^H \mathbf{u}\}\|^2 = \|V^H\mathbf{u} \|^2 = L_2
\end{equation}
Thus, we can use the iterative method proposed:
\begin{equation}
\mathbf{x}^{k+1}=\mathbf{x}^k +\left(\nabla g(\mathbf{x}^k)\nabla g(\mathbf{x}^k)^T\right)^{-1} \nabla g(\mathbf{x}^k) g(\mathbf{x}^k)
\end{equation}
Where:
\begin{equation}
\nabla g(\mathbf{x^k}) = \sqrt{2}
\begin{pmatrix} 
\nabla Re\{V^H\mathbf{u}\} \\ \nabla Im\{V^H\mathbf{u}\} 
\end{pmatrix}= \sqrt{2}
\begin{pmatrix} 
Re \{\nabla (V^H\mathbf{u})\} \\ Im\{\nabla (V^H\mathbf{u})\} 
\end{pmatrix}
\end{equation}
And:
\begin{equation}
\nabla V^H\mathbf{u}\ = -2 \pi j T_s \frac{f_c}{c}
\begin{pmatrix}  
\tilde{\Theta}_x V^H \tilde{N} \mathbf{u} &
\tilde{\Theta}_y V^H \tilde{N} \mathbf{u} &
\tilde{\Theta}_{v_x} V^H \tilde{N} \mathbf{u} &
\tilde{\Theta}_{v_y} V^H \tilde{N} \mathbf{u}
\end{pmatrix}
\end{equation}
Where: 
\begin{eqnarray}
\tilde{\Theta}_x = diag \left[-\frac{\|\vec{v}\|}{d_1} \sin \phi_1 \sin \theta_1, \dots ,-\frac{\|\vec{v}\|}{d_L} \sin \phi_L \sin \theta_L \right] \\
\tilde{\Theta}_y = diag \left[\frac{\|\vec{v}\|}{d_1} \sin \phi_1 \cos \theta_1, \dots ,\frac{\|\vec{v}\|}{d_L} \sin \phi_L \cos \theta_L \right]\\
\tilde{\Theta}_{v_x} = diag \left[cos \theta_1, \dots ,cos \theta_L \right] \\
\tilde{\Theta}_{v_y} = diag \left[sin \theta_1, \dots ,sin \theta_L \right]
\end{eqnarray}
Note that the direction used in the above iteration is a climb direction since 
$\nabla g(\mathbf{x}^k) g(\mathbf{x}^k)$ is the gradient at $\mathbf{x}^k$ of the cost function
$\frac{1}{2}\|g(\mathbf{x})\|^2$ and $\left(\nabla g(\mathbf{x}^k)\nabla g(\mathbf{x}^k)^T\right)^{-1}$ is a positive definite matrix.


\section{Known Wide Band Signals}

\subsection{Steepest Descent Method}

Implementing the steepest descent gradient based search method is very similar to the known narrow band signals scenario. The only difference is that the derivatives $\frac{\partial L_2}{\partial x}$ and $\frac{\partial L_2}{\partial y}$ that need to be used are the ones derived for the wide band known signals scenario in section (\ref{d_L2_dx_dy_WB}).

\subsection{Gauss-Newton Method}

In the wide-band known signals scenario, the derivatives $\frac{\partial L_2}{\partial x}$ and $\frac{\partial L_2}{\partial y}$ are more complex, and the expressions for the Gauss-Newton method in the entire position and velocity space are much less elegant.

Therefore, we can suggest to perform a grid search, or a steepest descent search in the position subspace, and employ the Gauss-Newton method in the velocity sub-space as follows.\\

Exactly like the at previous section, we have:
\begin{equation}
g(\mathbf{x})=\sqrt{2} \begin{pmatrix} Re\{V^H \mathbf{u}\} \\Im\{V^H \mathbf{u}\} \end{pmatrix}
\end{equation}

only that $\mathbf{x}$ contains only the velocity unknown parameters, meaning: 
\begin{equation}
\mathbf{x} \triangleq \left[ v_x, v_y \right]^T
\end{equation}

And therefore:
\begin{equation}
\nabla \triangleq \left[\frac{\partial}{\partial v_x},
\frac{\partial}{\partial v_y}\right]
\end{equation}

We can see that:
\begin{equation}
\frac{1}{2}\|g(\mathbf{x})\|^2=\|Re\{V^H \mathbf{u}\}\|^2+\|Im\{V^H \mathbf{u}\}\|^2 = \|V^H\mathbf{u} \|^2 = L_2
\end{equation}

We can use the iterative method suggested:
\begin{equation}
\mathbf{x}^{k+1}=\mathbf{x}^k +\left(\nabla g(\mathbf{x}^k)\nabla g(\mathbf{x}^k)^T\right)^{-1} \nabla g(\mathbf{x}^k) g(\mathbf{x}^k)
\end{equation}

Where:
\begin{equation}
\nabla g(\mathbf{x}^k) = 
\begin{pmatrix} 
\nabla Re\{V^H\mathbf{u}\} \\ \nabla Im\{V^H\mathbf{u}\} 
\end{pmatrix}=
\begin{pmatrix} 
Re \{\nabla V^H\mathbf{u}\} \\ Im\{\nabla V^H\mathbf{u}\} 
\end{pmatrix}
\end{equation}
And:
\begin{equation}
\nabla V^H\mathbf{u}\ = -2 \pi j T_s \frac{f_c}{c}
\begin{pmatrix}  
\tilde{\Theta}_{v_x} V^H \tilde{N} \mathbf{u} &
\tilde{\Theta}_{v_y} V^H \tilde{N} \mathbf{u}
\end{pmatrix}
\end{equation}
Where: 
\begin{eqnarray}
\tilde{\Theta}_{v_x} = diag \left[cos \theta_1, \dots ,cos \theta_L \right] \\
\tilde{\Theta}_{v_y} = diag \left[sin \theta_1, \dots ,sin \theta_L \right]
\end{eqnarray}

\section{Unknown Signals}
In the case of unknown signals, we do not have explicit expressions for the derivatives of the cost function $L_3$ in the position subspace or in the velocity subspace.
Therefore, we need to perform a grid search both in the velocity subspace and in the position subspace or we can perform a gradient search based method, where the gradient is derived numerically.

\section{Applying the Extended Kalman Filter}
\label{applying_kalman}
So far, we handled the semi-static scenario in which we did not take into consideration
the dynamic motion model of the transmitter. In the semi-static scenario we estimated
the position and velocity of the transmitter in one observation interval.\\
In this section, we will use a simple constant velocity dynamic motion model, together
with the extended Kalman filter, to take into consideration the motion of the transmitter
and to improve the position and velocity estimation of the transmitter over time.\\
We call this method - The Extnded Kalman Filter - because the measurement noise is not
necessarily Gaussian, although we assume it is.\\
In our scenario, the state vector is:

\begin{equation}
\mathbf{x} = \begin{pmatrix}x \\ v_x \\ y \\ v_y\end{pmatrix}
\end{equation}

We assume that between each step the transmitter undergoes a constant acceleration of $\mathbf{a_k}$ that is normally distributed, with zero mean and covariance matrix:

\begin{equation}
R = \begin{pmatrix} \sigma^2_{a_x} & 0 \\ 0 & \sigma^2_{a_y} \end{pmatrix}
\end{equation}

From Newton's Law:
\begin{equation}
\mathbf{x}_k = F \mathbf{x}_{k-1}+G\mathbf{a}_k
\end{equation}

Where:

\begin{equation}
F = 
\begin{pmatrix}
1 & \Delta t & 0 & 0\\
0 & 1 & 0 & 0\\
0& 0& 1 & \Delta t\\
0& 0& 0& 1
\end{pmatrix}
\end{equation}

And:

\begin{equation}
G = 
\begin{pmatrix} 
\frac{\Delta t^2}{2} & 0 \\
\Delta t & 0\\
0 & \frac{\Delta t^2}{2}\\
0& \Delta t\\
\end{pmatrix}
\end{equation}

So that:
\begin{equation}
\mathbf{x}_{k} = F \mathbf{x}_{k-1}+\mathbf{w}_{k}
\end{equation}

Where $\mathbf{w}_{k} \sim N(0,Q)$
\begin{eqnarray}
Q = GRG^T = \\
&=& \begin{pmatrix} 
\frac{\Delta t^2}{2} & 0 \\
\Delta t & 0\\
0 & \frac{\Delta t^2}{2}\\
0& \Delta t\\
\end{pmatrix} 
\begin{pmatrix} \sigma^2_{a_x} & 0 \\ 0 & \sigma^2_{a_y} \end{pmatrix}
\begin{pmatrix} 
\frac{\Delta t^2}{2} & 0 \\
\Delta t & 0\\
0 & \frac{\Delta t^2}{2}\\
0& \Delta t\\
\end{pmatrix} ^T  = \nonumber \\
&=& 
\begin{pmatrix}
\frac{\Delta t^2}{4}\sigma^2_{a_x} &\frac{\Delta t^3}{2}\sigma^2_{a_x} &0&0\\
\frac{\Delta t^3}{2}\sigma^2_{a_x} & \Delta t^2 \sigma^2_{a_x}&0&0 \\
0&0& \frac{\Delta t^2}{4}\sigma^2_{a_y} &\frac{\Delta t^3}{2}\sigma^2_{a_y}\\
0&0&\frac{\Delta t^3}{2}\sigma^2_{a_y} & \Delta t^2 \sigma^2_{a_y}
\end{pmatrix} \nonumber
\end{eqnarray}
At each time step, using one of the semi-static algorithm suggested in the previous sections, a
measurement of the position and velocity of the transmitter is made.
\\
Let us assume that measurement noise, caused by our estimation error, $\mathbf{\nu}_{k}$ is
zero mean, with covariance matrix $R_z$. We can use the CRB as an estimation for the measurement noise covariance matrix $R_z$.\\

Thus, our measurement model takes the form:
\begin{equation}
\mathbf{z}_{k} = H \mathbf{x}_{k}+ \mathbf{\nu}_{k}
\end{equation}
Where:
\begin{equation}
H=I
\end{equation}
Using the definitions above we can use the standard Kalman filter algorithm:
\\

Prediction for the state vector and variance:
\begin{eqnarray}
\mathbf{\hat{x}}_{{k|k-1}} = F \mathbf{\hat{x}}_{{k-1|k-1}}\\
\hat{P}_{k|k-1} = F \hat{P}_{k-1|k-1}F^T+Q
\end{eqnarray}

The Kalman gain factor:
\begin{equation}
K_k = \hat{P}_{k|k-1} H^T(H\hat{P}_{k|k-1}H^T+R_z)^{-1}
\end{equation}

Correction based on observation:
\begin{eqnarray}
\mathbf{\hat{x}}_{{k|k}} = \mathbf{\hat{x}}_{{k|k-1}} +K_k(\mathbf{z}_k-H\mathbf{\hat{x}}_{{k|k-1}})\\
\hat{P}_{k|k} = (I-K_kH)\hat{P}_{k|k-1}
\end{eqnarray}

For Initialization we can choose:
\begin{eqnarray*}
\mathbf{\hat{x}}_{0|0}=\mathbf{z}_0\\
P_{0|0} = CRB
\end{eqnarray*}
Where we use the first measurement as the best estimate for the position and velocity, and the Cramer-Rao lower bound as a good estimate for the estimator accuracy.

\chapter{CRAMER-RAO Lower Bound}
The Cramer-Rao Lower Bound is a lower bound on the covariance of any unbiased estimator. The bound is given by the inverse of the Fisher Information Matrix. 

\section{General CRAMER-RAO Lower Bound Formulation}
For complex Gaussian data vectors $\mathbf{r} \sim N(\mathbf{m},R)$ the elements of the Fischer Information Matrix are given by:

\begin{equation}
[J]_{ij}=tr\{ R^{-1}\frac{\partial R}{\partial \psi_{i}}R^{-1}\frac{\partial R}{\partial \psi_{j}}\}+2Re\{\frac{\partial \mathbf{m}^H}{\partial \psi_{i}}R^{-1}\frac{\partial \mathbf{m}}{\partial \psi_{j}}\}
\end{equation}

Where $\mathbf{\psi}$ is the unknown parameters vector and $R$ is the covariance matrix. in our case: 

\begin{equation*}
\mathbf{\psi} = \begin{pmatrix} x\\y\\v_x\\v_y\end{pmatrix}
\end{equation*}
\\
\begin{equation*}
R = diag \{\sigma_1^2 \cdot I,\dots,\sigma_L^2 \cdot I\}
\end{equation*}
\\

If we consider the signals as non-random variables, the data covariance is equal to the noise covariance which is independent of the unknown parameters, under the assumption that the noise covariance is known. \\
Thus, we get: 

\begin{equation}
[J]_{ij} =	2Re\{\frac{\partial \mathbf{m}^H}{\partial \psi_{i}}R^{-1}\frac{\partial \mathbf{m}}{\partial \psi_{j}}\}
\end{equation}

The data vector is given by:

\begin{equation}
\mathbf{m} \triangleq [\mathbf{m_1}^T,\dots ,\mathbf{m_\ell}^T]^T                                              
\end{equation}

where:

\begin{equation}
\mathbf{m_\ell}=b_\ell A_\ell F_\ell C \mathbf{s}=b_\ell A_\ell C F_\ell \mathbf{s} = b_\ell A_\ell C \mathbf{s_\ell}
\end{equation}


and:
\begin{equation}
\mathbf{s_\ell} \triangleq [s(t_1-T_\ell) \dots s(t_N-T_\ell)]^T                                                           
\end{equation}

Taking into account the structure of $R$ and $\mathbf{m_\ell}$ we get:
\begin{equation}
\frac{\partial \mathbf{m}^H}{\partial \psi_{i}}R^{-1}\frac{\partial \mathbf{m}}{\partial \psi_{j}} = 
\sum_{l=1}^L\frac{1}{\sigma_\ell^2}\frac{\partial \mathbf{m_\ell}}{\partial \psi_i}^H\frac{\partial \mathbf{m_\ell}}{\partial \psi_j}
\end{equation}

We are interested in the derivatives of $\mathbf{m}$ with respect to the target coordinates and velocity. Using the chain rule we can write:
\begin{equation}
\frac{\partial \mathbf{m_\ell}}{\partial \psi_i}=\frac{\partial \mathbf{m_\ell}}{\partial f_\ell}\frac{\partial f_\ell}{\partial \psi_i}+\frac{\partial \mathbf{m_\ell}}{\partial T_\ell}  \frac{\partial T_\ell}{\partial \psi_i}                                                                  
\end{equation}

\subsection{$\frac{\partial \mathbf{m_\ell}}{\partial f_\ell}$ derivation:}
\begin{equation}
\frac{\partial \mathbf{m_\ell}}{\partial f_\ell}=\frac{\partial}{\partial f_\ell} b_\ell A_\ell C \mathbf{s_\ell} = b_\ell ( \frac{\partial}{\partial f_\ell} A_\ell ) C \mathbf{s_\ell}
\end{equation}

Note that:
\begin{equation}
\frac{\partial}{\partial f_\ell}A_\ell = 2 \pi j T_s \tilde{N} A_\ell
\end{equation}

Where:
\begin{equation}
\tilde{N} \triangleq diag\{0,1,2,\dots,N-1\}
\end{equation}

So that:
\begin{equation}
\frac{\partial \mathbf{m_\ell}}{\partial f_\ell}=2 \pi j T_s b_\ell \tilde{N} A_\ell C \mathbf{s_\ell}
\end{equation}

\subsection{$\frac{\partial \mathbf{m_\ell}}{\partial T_\ell}$ derivation:}
\begin{equation}
\frac{\partial \mathbf{m_\ell}}{\partial T_\ell} =\frac{\partial}{\partial T_\ell} b_\ell  A_\ell C \mathbf{s_\ell}=b_\ell  A_\ell C \frac{\partial}{\partial T_\ell}\mathbf{s_\ell}
\end{equation}

Where:

\begin{equation}
\frac{\partial}{\partial T_\ell} \mathbf{s_\ell} = \frac{\partial}{\partial T_\ell} [s(t_1-T_\ell) \dots s(t_N-T_\ell)]^T=-[\dot{s}(t_1-T_\ell )\dots \dot{s}(t_N-T_\ell)]^T = -\mathbf{\dot{s_\ell}}
\end{equation}

$\dot{s(t)}$ represents the temporal derivative of the signal envelope $\frac{\partial s(t)}{\partial t}$ and we defined:
\begin{equation}
\dot{s_\ell}[n] \triangleq \frac{\partial}{\partial t} s(t)|_{t=nTs-T_\ell}
\end{equation}

So that:
\begin{equation}
\frac{\partial \mathbf{m_\ell}}{\partial T_\ell} = -b_\ell A_\ell C \mathbf{\dot{s_\ell}}
\end{equation}

\subsection{$\frac{\partial f_\ell}{\partial x}$, $\frac{\partial f_\ell}{\partial y}$,
$\frac{\partial f_\ell}{\partial v_x}$, $\frac{\partial f_\ell}{\partial v_y}$
 derivation:}
 Notice that:
\begin{equation}
\frac{\partial f_\ell}{\partial \psi_i} = \frac{\partial}{\partial \psi_i} f_c {\mu}_\ell (\vec{p},\vec{v})
\end{equation}

And that:

\begin{equation} 
(\frac{-c}{f_c})\frac{\partial}{\partial \psi_i} f_c \mu_\ell(\vec{p},\vec{v})=\frac{\partial}{\partial \psi_i}(\frac{\vec{v}(\vec{p}-\vec{p_\ell})}{\|\vec{p} -\vec{p_\ell}\|})                                                           
\end{equation}


\begin{equation}
\frac{\partial}{\partial x} (\frac{\vec{v}(\vec{p}-\vec{p_\ell})}{\|\vec{p}-\vec{p_\ell}\|})=\frac{\partial}{\partial x}(\frac{v_x (x-x_\ell )+v_y (y-y_\ell )}{\sqrt{(x-x_\ell )^2+(y-y_\ell )^2}})=-\frac{\|\vec{v}\|}{d_\ell}  sin \phi_\ell sin\theta_\ell
\end{equation}

\begin{equation}
\frac{\partial}{\partial y} (\frac{\vec{v}(\vec{p}-\vec{p_\ell})}{\|\vec{p}-\vec{p_\ell}\|})=\frac{\|\vec{v}\|}{d_\ell}  sin\phi_\ell cos\theta_\ell                                                           
\end{equation}

\begin{equation}
\frac{\partial}{\partial v_x} (\frac{\vec{v}(\vec{p}-\vec{p_\ell})}{\|\vec{p}-\vec{p_\ell}\|})=\frac{\partial}{\partial v_x} \frac{v_x(x-x_\ell )+v_y(y-y_\ell)}{\sqrt{(x-x_\ell )^2+(y-y_\ell )^2}}=\frac{x-x_\ell}{\sqrt{(x-x_\ell )^2+(y-y_\ell )^2}}=cos\theta_\ell
\end{equation}

\begin{equation}
\frac{\partial}{\partial v_y} \frac{\vec{v}(\vec{p}-\vec{p_\ell})}{\|\vec{p}-\vec{p_\ell}\|}=\frac{\partial}{\partial v_y}\frac{v_x (x-x_\ell )+v_y (y-y_\ell )}{\sqrt{(x-x_\ell )^2+(y-y_\ell )^2 )}}=\frac{y-y_\ell}{\sqrt{(x-x_\ell )^2+(y-y_\ell )^2}}=sin\theta_\ell
\end{equation}

Where $d_\ell$ denotes the distance between the emitter and the $\ell$-th receiver, $\phi_\ell$ is the angle between the emitter velocity and the line connecting the $\ell$-th receiver and the emitter. $\theta_\ell$ is the angle between the line connecting the $\ell$-th receiver and the emitter and the $x$-axis.

\subsection{$\frac{\partial T_\ell}{\partial x}$, $\frac{\partial T_\ell}{\partial y}$,
$\frac{\partial T_\ell}{\partial v_x}$, $\frac{\partial T_\ell}{\partial v_y}$
 derivation:}
 
Remember that:

\begin{equation}
T_\ell=\frac{1}{c} \|\vec{p}-\vec{p_\ell}\|
\end{equation}

\begin{equation}
\frac{\partial}{\partial x} T_\ell=\frac{1}{c}  \frac{\partial}{\partial x} \sqrt{(x-x_\ell )^2+(y-y_\ell )^2}=\frac{1}{c}\frac{x-x_\ell }{\sqrt{(x-x_\ell  )^2+(y-y_\ell )^2}}=\frac{1}{c} cos\theta_\ell                                
\end{equation}

\begin{equation}
\frac{\partial} {\partial y} T_\ell =\frac{1}{c}  \frac{\partial}{\partial y} \sqrt{(x-x_\ell  )^2+(y-y_\ell  )^2}=\frac{1}{c}\frac{y-y_\ell }{\sqrt{(x-x_\ell  )^2+(y-y_\ell  )^2}}=\frac{1}{c} sin\theta_\ell                                  
\end{equation}

Since $T_\ell $ is independent of $v_x$,$v_y$:
\begin{equation}
\frac{\partial}{\partial v_x}  T_\ell =\frac{\partial}{\partial v_y}  T_\ell =0
\end{equation}

For summary:
\begin{equation}
\frac{\partial f_\ell }{\partial x}=\frac{f_c}{c} \frac{\|\vec{v}\|}{d_\ell } sin\phi_\ell  sin\theta_\ell 
\end{equation}
\begin{equation}
\frac{\partial f_\ell }{\partial y}=-\frac{f_c}{c}  \frac{\|\vec{v}\|}{d_\ell }  sin\phi_\ell  cos\theta_\ell 
\end{equation}
\begin{equation}
\frac{\partial f_\ell }{\partial v_x}=-\frac{f_c}{c} cos\theta_\ell 
\end{equation}
\begin{equation}
\frac{\partial f_\ell }{\partial v_y}=-\frac{f_c}{c} sin\theta_\ell 
\end{equation}
\begin{equation}
\frac{\partial}{\partial x} T_\ell =\frac{1}{c} cos\theta_\ell 
\end{equation}
\begin{equation}
\frac{\partial}{\partial y} T_\ell =\frac{1}{c} sin\theta_\ell 
\end{equation}
\begin{equation}
\frac{\partial}{\partial v_x}  T_\ell =0
\end{equation}
\begin{equation}
\frac{\partial}{\partial v_y}  T_\ell =0
\end{equation}

\subsection{$\frac{\partial \mathbf{m_\ell }}{\partial v_x}$,$\frac{\partial \mathbf{m_\ell }}{\partial v_y}$ derivation}

Remembering that:
$\frac{\partial \mathbf{m_\ell }}{\partial v_x} = \frac{\partial \mathbf{m_\ell }}{\partial f_\ell }\frac{\partial f_\ell }{\partial v_x} + \frac{\partial \mathbf{m_\ell }}{\partial T_\ell }\frac{\partial T_\ell }{\partial v_x}$
we get:

\begin{equation}
\frac{\partial \mathbf{m_\ell }}{\partial v_x} = -(2 \pi j \frac{f_c}{c} cos\theta_\ell ) T_s b_\ell  \tilde{N} A_\ell  C \mathbf{s_\ell }
\end{equation}

And in the same manner, for $v_y$ we get:
\begin{equation}
\frac{\partial \mathbf{m_\ell }}{\partial v_y} = -(2 \pi j \frac{f_c}{c} sin\theta_\ell ) T_s b_\ell  \tilde{N} A_\ell  C \mathbf{s_\ell }
\end{equation}

\subsection{$\frac{\partial \mathbf{m_\ell }}{\partial x}$,$\frac{\partial \mathbf{m_\ell }}{\partial y}$ derivation}
Remembering that 
$\frac{\partial \mathbf{m_\ell }}{\partial x} = \frac{\partial \mathbf{m_\ell }}{\partial f_\ell }\frac{\partial f_\ell }{\partial x} + \frac{\partial \mathbf{m_\ell }}{\partial T_\ell }\frac{\partial T_\ell }{\partial x}$
we get:

\begin{equation}
\frac{\partial \mathbf{m_\ell }}{\partial x} = (2 \pi j T_s \frac{f_c}{c} \frac{\|\vec{v}\|}{d_\ell } sin\phi_\ell  sin\theta_\ell )b_\ell  \tilde{N} A_\ell  C \mathbf{s_\ell } -\frac{1}{c}cos\theta_\ell  b_\ell  A_\ell  C \dot{\mathbf{s_\ell }}
\end{equation}

And in the same manner, for $y$ we get:
\begin{equation}
\frac{\partial \mathbf{m_\ell }}{\partial y} = -(2 \pi j T_s \frac{f_c}{c} \frac{\|\vec{v}\|}{d_\ell } sin\phi_\ell  cos\theta_\ell )b_\ell  \tilde{N} A_\ell  C \mathbf{s_\ell } -\frac{1}{c}sin\theta_\ell  b_\ell  A_\ell  C \dot{\mathbf{s_\ell }}
\end{equation}


\section{Expression for $[J]_{v_x v_x}$ and $[J]_{v_y v_y}$ }


Substituting in the expression for $[J]_{v_x v_x}$ we get:
\begin{equation}
[J]_{v_x v_x} = 2\sum_{l=1}^{L}\frac{1}{\sigma_\ell ^2}\left\|\frac{\partial \mathbf{m_\ell }}{\partial v_x}\right\|^2
\end{equation}
Hence:
\begin{eqnarray}
\label{eq:j_v_x_v_x}
[J]_{v_x v_x} = \\
&=& 2\sum_{l=1}^{L}\frac{1}{\sigma_\ell ^2}(2 \pi T_s \frac{f_c}{c}cos\theta_\ell )^2 \|b_\ell \|^2 \mathbf{s_\ell }^H C^H A_\ell ^H \tilde{N}^H  \tilde{N} A_\ell  C \mathbf{s_\ell } = \nonumber \\
&=& 2\sum_{l=1}^{L}\frac{1}{\sigma_\ell ^2}(2 \pi T_s \frac{f_c}{c}cos\theta_\ell )^2 \|b_\ell \|^2 \mathbf{s_\ell }^H \tilde{N}^H  \tilde{N} \mathbf{s_\ell } = \nonumber \\
&=& 2\sum_{l=1}^{L}\frac{1}{\sigma_\ell ^2}(2 \pi T_s \frac{f_c}{c}cos\theta_\ell )^2 \|b_\ell \|^2  \|\tilde{N} \mathbf{s_\ell }\|^2 = \nonumber \\
&=& 2\sum_{l=1}^{L}\frac{\|b_\ell \|^2 \|\mathbf{s_\ell }\|^2}{N \sigma_\ell ^2}N(2 \pi T_s \frac{f_c}{c}cos\theta_\ell )^2  \frac{\|\tilde{N} \mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2} \nonumber \\
\end{eqnarray}

If we denote $B$ as the signal's bandwidth then according to the Nyquist theorem ${F_s} \geq 2B$.
Thus: $T_s \leq \frac{1}{2B}$. In order to minimize the lower-bound, we will choose $T_s = \frac{1}{2B}$, $N=\frac{T}{T_s}=2BT$ and substitute in (\ref{eq:j_v_x_v_x}).
Therefore:
\begin{eqnarray}
[J]_{v_x v_x} = \\
&=& 2\sum_{l=1}^{L}\frac{\|b_\ell \|^2 \|\mathbf{s_\ell }\|^2}{N \sigma_\ell ^2} 2BT(2 \pi \frac{1}{2B} \frac{f_c}{c}cos\theta_\ell )^2 \frac{\|\tilde{N} \mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2} = \nonumber \\
&=&4 \left(\pi \frac{f_c}{c}\right)^2 \frac{T}{B}  \sum_{l=1}^{L}SNR_\ell  cos^2\theta_\ell  \frac{\|\tilde{N} \mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2}
\end{eqnarray}

And similarly:
\begin{equation}
[J]_{v_y v_y} =4 \left(\pi \frac{f_c}{c}\right)^2 \frac{T}{B}  \sum_{l=1}^{L}SNR_\ell  sin^2\theta_\ell  \frac{\|\tilde{N} \mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2}
\end{equation}


\section{Expression for $[J]_{x x}$ and $[J]_{y y}$ }
Substituting in the expression for $[J]_{x x}$ we get:
\begin{equation}
[J]_{x x} = 2\sum_{l=1}^{L}\frac{1}{\sigma_\ell ^2}\left\|\frac{\partial \mathbf{m_\ell }}{\partial x} \right\|^2
\end{equation}
Hence:
\begin{eqnarray}
[J]_{x x} = \\
&=& 2\sum_{l=1}^{L}\frac{1}{\sigma_\ell ^2} \left[\ \left(2 \pi T_s \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  \right)^2 \|b_\ell \|^2\|\tilde{N}\mathbf{s_\ell }\|^2+ \left( \frac{1}{c} cos\theta_\ell  \right)^2 \|b_\ell \|^2\|\mathbf{\dot{s_\ell }}\|^2 - (*) - (*)^H \right] \nonumber
\end{eqnarray}

Where:

\begin{eqnarray}
(*) = \\
&=& \left[ \left( 2 \pi j T_s \frac{f_c}{c} \frac{\|\vec{v}\|}{d_\ell } sin\phi_\ell  sin\theta_\ell  \right) b_\ell  \tilde{N} A_\ell  C \mathbf{s_\ell } \right]^H 
\left[ \frac{1}{c} cos \theta_\ell  b_\ell  A_\ell  C \mathbf{\dot{s_\ell }} \right] \nonumber \\
&=& -2 \pi j T_s \frac{f_c}{c^2} \frac{\|\vec{v}\|}{d_\ell } sin\phi_\ell  sin \theta_\ell  cos\theta_\ell  \|b_\ell \|^2  \mathbf{s_\ell }^H \tilde{N} \mathbf{\dot{s_\ell }} \nonumber
\end{eqnarray}

And therefore:
\begin{eqnarray}
(*) + (*)^H = \\
&=& -2 \pi T_s \frac{f_c}{c^2}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  cos \theta_\ell  \|b_\ell \|^2 (j \mathbf{s_\ell }^H\tilde{N}\mathbf{\dot{s_\ell }}-j \mathbf{\dot{s_\ell }}^H\tilde{N}^H\mathbf{s_\ell }) = \nonumber \\
&=& 4 \pi T_s \frac{f_c}{c^2}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  cos \theta_\ell  \|b_\ell \|^2 IM\{\mathbf{s_\ell }^H\tilde{N}\mathbf{\dot{s_\ell }}\} \nonumber
\end{eqnarray}


Hence:
\begin{eqnarray}
[J]_{x x} = \\
&= 2\sum_{l=1}^{L}\frac{1}{\sigma_\ell ^2} [\ \left(2 \pi T_s \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  \right)^2 \|b_\ell \|^2\|\tilde{N}\mathbf{s_\ell }\|^2+ \dots \nonumber \\
&\dots+ \left( \frac{1}{c} cos\theta_\ell  \right)^2 \|b_\ell \|^2\|\mathbf{\dot{s_\ell }}\|^2 - \dots \nonumber \\
&\dots - 4 \pi T_s \frac{f_c}{c^2}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  cos \theta_\ell  \|b_\ell \|^2 \Im\{\mathbf{s_\ell }^H\tilde{N}\mathbf{\dot{s_\ell }}\} ] \nonumber
\end{eqnarray}

And so:
\begin{eqnarray}
[J]_{x x} = \\
&= 2\sum_{l=1}^{L}\frac{\|b_\ell \|^2\|\mathbf{s_\ell }\|^2}{N \sigma_\ell ^2} N [\ \left(2 \pi T_s \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  \right)^2 \frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2}+ \dots \nonumber \\
&\dots+ \left( \frac{1}{c} cos\theta_\ell  \right)^2 \frac{\|\mathbf{\dot{s_\ell }}\|^2}{\|\mathbf{s_\ell }\|^2} - \dots \nonumber \\
&\dots - 4 \pi T_s \frac{f_c}{c^2}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  cos \theta_\ell  \frac{\Im\{\mathbf{s_\ell }^H\tilde{N}\mathbf{\dot{s_\ell }}\}}{\|\mathbf{s_\ell }\|^2} ] \nonumber
\end{eqnarray}

Thus:
\begin{eqnarray}
[J]_{x x} = \\
&= 2\sum_{l=1}^{L}{SNR}_\ell 2BT [\ \left(2 \pi \frac{1}{2B} \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  \right)^2 \frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2}+ \dots \nonumber \\
&\dots+ \left( \frac{1}{c} cos\theta_\ell  \right)^2 \frac{\|\mathbf{\dot{s_\ell }}\|^2}{\|\mathbf{s_\ell }\|^2} - \dots \nonumber \\
&\dots - 4 \pi \frac{1}{2B} \frac{f_c}{c^2}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  cos \theta_\ell  \frac{\Im\{\mathbf{s_\ell }^H\tilde{N}\mathbf{\dot{s_\ell }}\}}{\|\mathbf{s_\ell }\|^2} ] \nonumber
\end{eqnarray}

\begin{eqnarray}
[J]_{x x} = \\
&= 4\frac{T}{B} \sum_{l=1}^{L}{SNR}_\ell  [\ \left( \pi \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  \right)^2 \frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2}+ \dots \nonumber \\
&\dots+ B^2\left( \frac{1}{c} cos\theta_\ell  \right)^2 \frac{\|\mathbf{\dot{s_\ell }}\|^2}{\|\mathbf{s_\ell }\|^2} - \dots \nonumber \\
&\dots - 2 \pi B \frac{f_c}{c^2}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  cos \theta_\ell  \frac{\Im\{\mathbf{s_\ell }^H\tilde{N}\mathbf{\dot{s_\ell }}\}}{\|\mathbf{s_\ell }\|^2} ] \nonumber
\end{eqnarray}

Similarly:
\begin{eqnarray}
[J]_{y y} = \\
&= 4\frac{T}{B} \sum_{l=1}^{L}{SNR}_\ell  [\ \left( \pi \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  cos\theta_\ell  \right)^2 \frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2}+ \dots \nonumber \\
&\dots+ B^2\left( \frac{1}{c} sin\theta_\ell  \right)^2 \frac{\|\mathbf{\dot{s_\ell }}\|^2}{\|\mathbf{s_\ell }\|^2} + \dots \nonumber \\
&\dots + 2 \pi B \frac{f_c}{c^2}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin\theta_\ell  cos \theta_\ell  \frac{\Im\{\mathbf{s_\ell }^H\tilde{N}\mathbf{\dot{s_\ell }}\}}{\|\mathbf{s_\ell }\|^2} ] \nonumber
\end{eqnarray}

\section{Expression for $[J]_{x v_x}$ ,$[J]_{y v_y}$,$[J]_{x v_y} $ and $[J]_{y v_x} $}
\begin{eqnarray}
\left(\frac{\partial \mathbf{m_\ell }}{\partial x} \right)^H \left(\frac{\partial \mathbf{m_\ell }}{\partial v_x} \right) = \\
&=&\left[(2 \pi j T_s \frac{f_c}{c} \frac{\|\vec{v}\|}{d_\ell } sin\phi_\ell  sin\theta_\ell )b_\ell  \tilde{N} A_\ell  C \mathbf{s_\ell } -\frac{1}{c}cos\theta_\ell  b_\ell  A_\ell  C \dot{\mathbf{s_\ell }}\right]^H \cdot \nonumber \\
&\cdot& \left[ -(2 \pi j \frac{f_c}{c} cos\theta_\ell ) T_s b_\ell  \tilde{N} A_\ell  C \mathbf{s_\ell } \right] = \nonumber \\
&=& \|b_\ell \|^2\|s_\ell \|^2 [ -\left(2 \pi T_s \frac{f_c}{c}\right)^2\left(\frac{\|\vec{v}\|}{d_\ell } sin \phi_\ell  sin \theta_\ell  cos \theta_\ell \right)\frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|2} +\dots \nonumber\\
&&\dots +\left(\frac{1}{c}cos \theta_\ell \right)^2(2 \pi f_c T_s)j \frac{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }}{\|\mathbf{s_\ell }\|^2} ]
 \nonumber
\end{eqnarray}
Hence:
\begin{eqnarray}
[J]_{x v_x} = \\
&=& 2\sum_{l=1}^L\frac{\|b_\ell \|^2\|s_\ell \|^2}{N\sigma_\ell ^2}N[ -\left(2 \pi T_s \frac{f_c}{c}\right)^2\left(\frac{\|\vec{v}\|}{d_\ell } sin \phi_\ell  sin \theta_\ell  cos \theta_\ell \right)\frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|2} -\dots \nonumber\\
&&\dots -\left(\frac{1}{c}cos \theta_\ell \right)^2(2 \pi f_c T_s) \Im \left\{\frac{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }}{\|\mathbf{s_\ell }\|^2} \right\}]
 \nonumber \\
 &=& 4\frac{T}{B} \sum_{l=1}^L{SNR}_\ell  [ -\left( \pi \frac{f_c}{c}\right)^2\left(\frac{\|\vec{v}\|}{d_\ell } sin \phi_\ell  sin \theta_\ell  cos \theta_\ell \right)\frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|2} -\dots \nonumber\\
&&\dots -\left(\frac{1}{c}cos \theta_\ell \right)^2( \pi f_c B) \Im \left\{\frac{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }}{\|\mathbf{s_\ell }\|^2} \right\}]
 \nonumber
\end{eqnarray}

And similarly:
\begin{eqnarray}
[J]_{y v_y} = \\
&&4\frac{T}{B} \sum_{l=1}^L{SNR}_\ell  [ \left( \pi \frac{f_c}{c}\right)^2\left(\frac{\|\vec{v}\|}{d_\ell } sin \phi_\ell  sin \theta_\ell  cos \theta_\ell \right)\frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|2} -\dots \nonumber\\
&&\dots -\left(\frac{1}{c}sin \theta_\ell \right)^2( \pi f_c B) \Im \{\frac{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }}{\|\mathbf{s_\ell }\|^2}\} ]
 \nonumber
\end{eqnarray}

\begin{eqnarray}
[J]_{x v_y} = \\
&=& 4\frac{T}{B} \sum_{l=1}^L{SNR}_\ell  [ -\left( \pi \frac{f_c}{c}\right)^2\left(\frac{\|\vec{v}\|}{d_\ell } sin \phi_\ell  sin^2 \theta_\ell \right)\frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|2} -\dots \nonumber\\
&&\dots -\left(\frac{1}{c}\right)^2 sin \theta_\ell  cos \theta_\ell ( \pi f_c B) \Im \{ \frac{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }}{\|\mathbf{s_\ell }\|^2} \}]
 \nonumber
\end{eqnarray}
\begin{eqnarray}
[J]_{y v_x} = \\
&=& 4\frac{T}{B} \sum_{l=1}^L{SNR}_\ell  [ \left( \pi \frac{f_c}{c}\right)^2\left(\frac{\|\vec{v}\|}{d_\ell } sin \phi_\ell  cos^2 \theta_\ell \right)\frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|2} -\dots \nonumber\\
&&\dots -\left(\frac{1}{c}\right)^2 sin \theta_\ell  cos \theta_\ell ( \pi f_c B) \Im \{ \frac{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }}{\|\mathbf{s_\ell }\|^2}\} ]
 \nonumber
\end{eqnarray}

\section{Expression for $[J]_{x y}$ and $[J]_{v_x v_y}$ }
Similarly to the previous sections:
\begin{eqnarray}
\left(\frac{\partial \mathbf{m_\ell }}{\partial x}\right)^H\left(\frac{\partial \mathbf{m_\ell }}{\partial y}\right) &=& \\
&=& -(2 \pi T_s \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell )^2 sin\theta_\ell  cos\theta_\ell  |b_\ell |^2\|\tilde{N}\mathbf{s_\ell }\|^2 + \dots \nonumber\\
&&\dots + \frac{1}{c^2}sin \theta_\ell  cos\theta_\ell  |b_\ell |^2\|\mathbf{\dot{s_\ell }}\|^2 +\dots \nonumber \\
&&\dots + (2 \pi T_s \frac{f_c}{c^2} \frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell )(j+2sin^2\theta_\ell \Im\{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }\})\nonumber
\end{eqnarray}
Thus:
\begin{eqnarray}
[J]_{xy} &=& \\
&=& 2 \sum_{l=1}^L \frac{|b_\ell |^2\|\mathbf{s_\ell }\|^2}{N\sigma_\ell ^2}N[-(2 \pi T_s \frac{f_c}{c}\frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell )^2 sin\theta_\ell  cos\theta_\ell  |b_\ell |^2\|\tilde{N}\mathbf{s_\ell }\|^2 + \dots \nonumber\\
&&\dots + \frac{1}{c^2}sin \theta_\ell  cos\theta_\ell  |b_\ell |^2\|\mathbf{\dot{s_\ell }}\|^2 +\dots \nonumber \\
&&\dots + 4 \pi T_s \frac{f_c}{c^2} \frac{\|\vec{v}\|}{d_\ell }sin\phi_\ell  sin^2\theta_\ell \Im\{\mathbf{\dot{s_\ell }}^H\tilde{N}\mathbf{s_\ell }\}]\nonumber
\end{eqnarray}

And:
\begin{equation}
\left(\frac{\partial \mathbf{m_\ell }}{\partial v_x}\right)^H\left(\frac{\partial \mathbf{m_\ell }}{\partial v_y}\right) =
 - (2 \pi \frac{f_c}{c} T_s)^2 sin\theta_\ell  cos \theta_\ell  |b_\ell |^2 \|\tilde{N}\mathbf{s_\ell }\|^2 
 \end{equation}
Thus:
\begin{equation}
[J]_{v_xv_y} = -4\frac{T}{B} ( \pi \frac{f_c}{c})^2\sum_{l=1}^L {SNR}_\ell   sin\theta_\ell  cos \theta_\ell   \frac{\|\tilde{N}\mathbf{s_\ell }\|^2}{\|\mathbf{s_\ell }\|^2}
\end{equation}
\chapter{Numerical Results}
\section{Semi-Static Scenario}
We define the scenario in which we estimate the position and velocity of the transmitter at a signal snapshot as the Semi-Static Scenario. The scenario is not static because the transmitter 
has a non-zero velocity, and yet, we assume that during the entire snapshot, the location
of the moving transmitter is fixed.

We define the scenario in which we estimate the position and velocity of the transmitter using data
from several snapshots as the Dynamic Scenario.

\subsection{Performance vs. SNR}
\subsection{Performance vs. Antenna Elements - Circular Array}
\subsection{Performance vs. Antenna Elements - Linear Array}
\subsection{Performance vs. Bandwidth}
\subsection{Performance vs. Transmitter Distance}
\subsection{Performance vs. Transmitter velocity}
\subsection{Performance vs. Observation Time}
\section{Dynamic Scenario}
\subsection{Performance vs. Number of Observations}
\cite{porat}
\chapter{Summary and Future Work}

\bibliographystyle{plain}
\bibliography{thesis}

\end{document}
